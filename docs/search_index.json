[["index.html", "Statistical Modeling for Clinical Researchers Introduction", " Statistical Modeling for Clinical Researchers Albert Cobos Introduction This is an introductory book on statistical or probabilistic modeling for clinical researchers. There is a wide variety of statistical models, but this book covers only a few of them that are most frequently used in clinical research: the general linear model (GLM), the logistic regression model (LRM), and the Cox regression model (CRM). In many statistical models, statistical models express a variable (or a function of a variable) \\(Y\\) as a function of some other variables (\\(X_1, X_2, ..., X_k\\)). For instance, in the GML, a \\(Y\\) variable is expressed as a function of \\(X\\) variables plus an error term (\\(\\epsilon\\)): \\[Y = f(X_1, X_2, ..., X_k) + \\epsilon\\] Where, \\(Y\\) is called the dependent, predicted, explained or outcome variable. \\(X_1, X_2, ..., X_k\\) are called independent, predictor, or explanatory variables, and \\(\\epsilon\\) is a random variable with assumed to have a normal distribution. Because attempts to express a \\(Y\\) variable as a function of others are usually imperfect, the error term in the model represents the difference between the value of \\(Y\\) actually observed for an individual, and the prediction obtained from the explanatory variables (denoted by \\(\\hat{Y}\\)) : \\[\\epsilon = Y - f(X_1, X_2, ..., X_k) = Y - \\hat{Y}\\] Statistical modeling may be undertaken with two different goals, explanation or prediction, though in some cases both may be of interest. An example of an explanatory approach to modeling might be to understand why there is such a high variability in the number of daily births registered in the USA (in a particular year, this number ranged from about 7000 births to more than 10000 ), and what factors could explain it. In some cases, the relationships between the explanatory variables and the outcome variable are complex, and phenomena such as non-linearity, confounding or interactions can be explored via statistical models. An example of predictive modeling is the derivation of the Friedewald formula to estimate the blood concentration of LDL-cholesterol from the total cholesterol, HDL-cholesterol and triglycerides concentrations. Another example of predictive modeling is the determination of normal ranges for the forced expiratory volume (FEV, a spirometric measure of lung function) in healthy children, from gender, age and body height. The types of models we will cover differ mainly in the type of outcome variable (\\(Y\\)) we want to model. In a general linear model, the \\(Y\\) variable is continuous. The GLM includes as particular cases many classical analysis techniques, such as the t-test or the analysis of variance (in which the \\(X\\) variable(s) are categorical), the multiple linear regression analysys (in which \\(X\\) variables are continuous), and the analysis of covariance (in which some \\(X\\) variables are categorical and some are continuous). In the LRM the outcome variable is dichotomous, such as success or failure of a treatment. Last, in the CRM (also called Cox proportional hazards model) the outcome variable is the time until an event occurs, be it death or other. In all these types of models, the explanatory variables can be categorical, quantitative, or a mixture of both. Finally, a warning on terminology. The term generalized linear model is sometimes used to refer to a family of models that includes as particular cases the GLM, the LRM, and some other models, but not the CRM. Beware not to confuse generalized linear models with the general linear model, which is a particular case of the former. In many books on generalized linar models, the acronim GLM is used. However, in this book we use GLM as an acronim for the general linear model. "],["the-general-linear-model-glm.html", "1 The general linear model (GLM) 1.1 Data 1.2 Fitting a GLM 1.3 Inference on the model coefficients 1.4 Goodness-of-fit 1.5 Assessing assumptions 1.6 Probability intervals (or prediction intervals) 1.7 Models with two continuous predictors 1.8 Comparing models 1.9 Confounding 1.10 Interaction (effect modification) Resources Exercises", " 1 The general linear model (GLM) The general linear model (GLM) is a generalization of the simple linear regression model, allowing for more than one explanatory variable. In a GLM, a continuous outcome variable \\(Y\\) is expressed as a linear function of a set of explanatory or predictor variables \\(X\\), plus a random error term assumed to be normally distributed with constant variance \\(\\sigma^2\\): \\[\\begin{equation} Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p + \\epsilon \\qquad \\qquad \\epsilon \\sim N(0, \\sigma^2) \\tag{1.1} \\end{equation}\\] The deterministic part of the model (i.e., all terms but the random error term) provides predicted values (denoted as \\(\\hat{Y}\\)) for a given combination of \\(X\\) values, and these predictions are interpreted as the mean value of \\(Y\\) for all individuals with the given combination of \\(X\\) values: \\[\\hat{Y} = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p\\] So that the error terms in the model are just the difference between observed and predicted \\(Y\\) values: \\[\\epsilon = Y - \\hat{Y}\\] In the previous equations, the betas are the model coefficients or parameters, and our purpose will be to estimate these parameters, as well as the variance of the errors (\\(\\sigma^2\\)), from a sample of individuals in whom we have measured both the outcome variable \\(Y\\) and the explanatory variables \\(X_1, X_2, ..., X_p\\). Each of these coefficients is interpreted as the effect of the corresponding \\(X\\) variable on \\(Y\\), given all other \\(X\\) variables (i.e., when all other \\(X\\) variables are held constant). Explanatory variables in a GLM can be either quantitative or categorical. While there is no problem in entering a quantitative variable in the model equation, categorical variables cannot be entered as such. For instance, consider a model for variable height (cm) expressed as a function of variables age (years) and gender (male/female): \\[predicted\\quad height = \\beta_0 + \\beta_1 \\times age + \\beta_2 \\times gender\\] How are we supposed to compute the last term, if gender takes values \"male\" or \"female\"? To solve this problem, categorical variables, defined as factors in R, are used to create a set of dummy variables for each level of the factor but the first one. So, if gender has two levels only and the first level is \"male\", an indicator for \"female\" will be created (and named \\(genderfemale\\)), taking value 1 for females, and 0 for males. Then, the model actually fitted will be: \\[predicted\\quad height = \\beta_0 + \\beta_1 \\times age + \\beta_2 \\times genderfemale\\] Now, because \\(genderfemale\\) takes values 0 or 1, it is clear how to compute the predicted height for any individual. For instance, the predicted height for a 45 years female will be \\[\\beta_0 + \\beta_1 \\times 45 + \\beta_2 \\times 1 \\quad = \\quad \\beta_0 + \\beta_1 \\times 45 + \\beta_2\\], but for a 45 years male it will be \\[\\beta_0 + \\beta_1 \\times 45 + \\beta_2 \\times 0 \\quad = \\quad \\beta_0 + \\beta_1 \\times 45\\] In general, we will need \\(k-1\\) indicators to enter a factor with \\(k\\) levels in a model. For instance, suppose we want to include an explanatory factor race having levels \"white\", \"black\", \"asian\" and \"other\". In this case, we need three indicators, one for each of the levels but the first one (\"black\", \"asian\" and \"other\"), taking values 0 or 1 depending on race, as shown in table 1.1. Table 1.1: Indicators for race race black asian other white 0 0 0 black 1 0 0 asian 0 1 0 other 0 0 1 Thus, a model including the factor race would in fact have the following three terms to represent it (and possibly other explanatory variables): \\[\\beta_0 + \\beta_1 \\; raceblack + \\beta_2 \\; raceasian + \\beta_3 \\; raceother \\;+ \\; ... (other \\quad predictors)\\] In such a model, the predicted value for an individual depends on the value of race: when race is \"white\": \\(\\qquad \\beta_0 \\; + \\qquad \\; ... (other \\quad predictors)\\) when race is \"black\": \\(\\qquad\\beta_0 + \\beta_1 \\; + \\;... (other \\quad predictors)\\) when race is \"asian\": \\(\\qquad\\beta_0 + \\beta_2 \\; + \\;... (other \\quad predictors)\\) when race is \"other\": \\(\\qquad\\beta_0 + \\beta_3 \\; + \\;... (other \\quad predictors)\\) Fortunately, we do not need to compute these indicators to enter a categorical variable into a model. Provided the categorical variable is a factor, modeling functions such as lm() will compute them for us. In GLMs, the model parameters (i.e., the \\(\\beta\\) coefficients and the variance of the residuals \\(\\sigma^2\\)) are estimated so as to minimize the sum of the squares of the residuals. This criterion is known as least squares or ordinary least squares (OLS). 1.1 Data The lungcap dataset from package GLMsData (see ?lungcap) has data on the forced expiratory volume (a measure of lung capacity, expressed in litres) in 654 youth, as well as their gender and age, body height (in inches) and smoking habit. The following script gets the data, computes a new variable height (by converting inches to centimeters), defines factors for gender and smoke, saves the result as dataframe d, removes dataframe lungcap, and gets a summary of d: library(tidyverse) library(GLMsData) data(lungcap) # get the dataset d &lt;- lungcap %&gt;% janitor::clean_names() %&gt;% mutate(height = round(2.54 * ht), # converts from inches to cm gender = as.factor(gender), # creates factor for gender smoke = factor(smoke, # creates factor for smoke levels = 0:1, labels = c(&quot;no&quot;, &quot;yes&quot;))) %&gt;% select(-ht) # drops ht rm(lungcap) # removes lungcap summary(d) # summarizes d age fev gender smoke height Min. : 3.000 Min. :0.791 F:318 no :589 Min. :117.0 1st Qu.: 8.000 1st Qu.:1.981 M:336 yes: 65 1st Qu.:145.0 Median :10.000 Median :2.547 Median :156.0 Mean : 9.931 Mean :2.637 Mean :155.3 3rd Qu.:12.000 3rd Qu.:3.119 3rd Qu.:166.0 Max. :19.000 Max. :5.793 Max. :188.0 The summary shows that the age ranges from 3 to 19 years, males an females are about balanced in number, and there are few smokers. Suppose our goal is to establish normal ranges for the forced expiratory volume according to height and gender. Because smoking can impair the lung function, we want to exclude 65 smoking individuals from our analysis, so we subset dataframe d into dns (d non-smokers): dns &lt;- filter(d, smoke == &quot;no&quot;) Before undertaking any modelling exercise, let’s explore the relations of fev with height, age, and gender: library(ggformula) plot1 &lt;- gf_point(fev ~ age, data = dns, alpha=0.2) plot2 &lt;- gf_point(fev ~ height, data = dns, alpha=0.3) plot3 &lt;- gf_boxplot(fev ~ gender, data =dns) library(patchwork) plot1 + plot2 + plot3 Figure 1.1: Relations of FEV with age, height and gender in non-smokers In figure 1.1 (left), fev shows a quite strong, about linear relation with age , and even stronger with height (center), though a bit curvilinear. Also, the variability of fev seems to increase with both age and height. The distribution of fev values in men and women (right) are much overlapped, although in the former it extends to higher values. The non-linearity of the relation between fev and height, as well as the heteroscedasticity of fev with both age and height, are indications that the GLM model assumptions will not be met. But let’s start simple and fit a GLM anyway; later on we will see how to improve our analysis. 1.2 Fitting a GLM A GLM can be fitted with function lm(), by specifying the model in a formula as the first argument, and the dataframe in a second data= argument. The following script fits a model of fev based on height and gender, saves it as model1 and then prints it: model1 &lt;- lm(fev ~ height + gender, data = dns) model1 Call: lm(formula = fev ~ height + gender, data = dns) Coefficients: (Intercept) height genderM -5.33027 0.05093 0.10568 When we print a model object like model1, the estimates of the model Coefficients are shown. From these, the estimated regression equation is: predicted fev = -5.33027 + 0.05093 height + 0.10568 genderM The interpretation of the model coefficients is as follows: The intercept is the predicted fev for any observation having all explanatory variables equal to zero. In the example we are considering this interpretation is of no use, since zero is an impossible value for height. The coefficient for height means that, given the gender of an individual (or, for any gender), a unit increase in height (1 cm) will result in an increase of 0.05093 liters in the predicted fev value. The coefficient for genderM means that, given the height of an individual (or, for any height), the predicted value of fev for a male will be 0.10568 liters more than for a female. Model coefficients are sometimes refered to as the effect of the corresponding \\(X\\) variable on the predicted \\(Y\\) variable. So, 0.05093 is said to be the effect of height on the predicted fev, and 0.10568 is the effect of being male on the predicted fev. 1.2.1 Predicted values Using the equation we got in the previous section we can obtain predictions of the fev given height and genderM (coded as 0 for females, and 1 for males). Although we could use the equation to calculate ourselves the predictions of all the observations in the data frame, the predict() function (with the model object as argment) will do it for us. The result will be a vector with as many elements as rows in the dataframe used to fit the model (dnsin this case). Here we use head() to limit the output of the predictions to the first six cases in dns: predict(model1) %&gt;% head() 1 2 3 4 5 6 0.6287320 0.8833903 0.8833903 0.8833903 0.9852537 0.9852537 A graphical representation of the fitted model is shown in figure 1.2. Note the use of predict() in gf_line() to overlay predictions on the scatterplot of fev by height. As you see, the graphical appearance of model1 is that of two straight lines, one for males and another one for females, having identical slope but different intercept. library(ggformula) gf_point(fev ~ height, col = ~ gender, data =dns, alpha = 0.3) %&gt;% gf_line(predict(model1) ~ height, col = ~ gender, data = dns) Figure 1.2: Graphical representation of model 1 By default, function predict() computes predictions for the observations (rows) in the dataframe used to fit the model, but it can be used also to compute predictions for arbitrary values of the explanatory variables. To this end, we need to use the optional argument newdata, passing it a dataframe with the combinations of values of explanatory variables for which we want to compute the prediction. In this dataframe, the predictor variables should have the same name as in the dataset used to fit the model. Here we prepare a new dataframe with height values of 150, 160, 170, and 180 cm, for both boys and girls: # create dataframe with desired combinations of predictors (x) x &lt;- data.frame(height = rep(seq(150, 180, 10), each=2), gender = rep(c(&quot;M&quot;, &quot;F&quot;), each = 2)) x height gender 1 150 M 2 150 M 3 160 F 4 160 F 5 170 M 6 170 M 7 180 F 8 180 F Now we can use dataframe x to compute the predicted fev values for each of its combinations of height and sex values: predict(model1, newdata = x) 1 2 3 4 5 6 7 8 2.415154 2.415154 2.818794 2.818794 3.433787 3.433787 3.837427 3.837427 If desired, these predictions could be incorporated into dataframe x using predict() in a mutate() statement: x %&gt;% mutate(predicted_fev = predict(model1, newdata = x)) height gender predicted_fev 1 150 M 2.415154 2 150 M 2.415154 3 160 F 2.818794 4 160 F 2.818794 5 170 M 3.433787 6 170 M 3.433787 7 180 F 3.837427 8 180 F 3.837427 1.2.2 Residuals The residuals of a fitted model are estimates of the model error terms (\\(\\epsilon\\)) in the population equation. For any observation, the residual (\\(e\\)) is computed as the difference between the observed value (\\(Y\\)) and the value predicted by the model (\\(\\hat{Y}\\)): \\[e = Y - \\hat{Y}\\] Figure 1.3 shows the graphical representation of model1 (just as in figure 1.2), but now in two different panels for females (F) and males (M). The black lines are the same lines appearing in figure 1.2. For each observation, the vertical distance between the observed fev value (dots) and the corresponding predicted value (black lines) is displayed as a red line segment to represent its residual value. For all dots above the lines, the observed fev value is greater than the predicted value, and therefore the residual will be positive. Conversely, for all dots below the line, the observed value is lower than the predicted value, and therefore the residual will be negative. Any dot that lie exactly on the line have equal observed and predicted values, and therefore its residual value is zero. gf_point(fev ~ height | gender, data =dns, alpha = 0.2) %&gt;% gf_line(predict(model1) ~ height, data = dns) + geom_segment(aes(xend = height, yend = predict(model1), color = &quot;resid&quot;)) + scale_color_manual(values = c(resid = &quot;darkred&quot;), labels = c(resid = &quot;residuals&quot;)) Figure 1.3: Graphical representation of model 1 and residuals The residuals of the model can be obtained with function resid() applied to the model object model1, as done below (again, we use head() to limit the output to the residuals of the first six cases in dns): resid(model1) %&gt;% head() 1 2 3 4 5 6 0.44326801 -0.04439034 0.21860966 0.50560966 0.59174632 0.43274632 We can easily verify that residuals are nothing but the difference of observed and predicted values. Note that now we get exactly the same values listed above using resid(): obs_minus_pred &lt;- dns$fev - predict(model1) head(obs_minus_pred) 1 2 3 4 5 6 0.44326801 -0.04439034 0.21860966 0.50560966 0.59174632 0.43274632 1.3 Inference on the model coefficients It is important to understand that the equation obtained in the previous section 1.2 is an estimate of the population equation (that is, what we would get if we could fit the model with all individuals in the population). We may want to answer questions about the model coefficients in the population equation, such as: What are likely values of model coefficients in the population equation? What are likely values of the model predictions in the population equation? Could some model coefficients be equal to zero in the population equation? Could all model coeffcients be equal to zero in the population equation? The first two questions above are estimation questions, and the last two can be solved with appropriate significante tests. We address each of these questions in the following subsections. 1.3.1 Confidence intervals (CI) for the model coefficients Confidence intervals for the model coefficients can be easily obtained with function confint() applied to a model object: confint(model1) 2.5 % 97.5 % (Intercept) -5.69151579 -4.96903077 height 0.04856692 0.05329642 genderM 0.03760899 0.17374504 The output shows the lower (2.5%) and upper (99.5%) limits of the 95% CI for each coefficient in model1. The interpretation is as usual for a CI: we are 95% confident that (rounding to the fourth decimal): for any given gender, a unit increase in height (1 cm) will result in an increase of 0.0486 to 0.0533 liters in the predicted FEV. for any given height, the predicted value of FEV for a male will be between 0.0376 and 0.1737 liters more than for a female. CI’s can be computed for any desired confidence level using the argument level in confint(). For instance, here we compute the 99% CI for the model coefficients. Note that the confidence level has to be specified as a probability rather than as a percentage: confint(model1, level = 0.99) 0.5 % 99.5 % (Intercept) -5.80559378 -4.85495278 height 0.04782015 0.05404319 genderM 0.01611356 0.19524047 1.3.2 Confidence intervals (CI) for the model predictions A CI can also be obtained for each possible model prediction. Because a model prediction is interpreted as the expected or mean FEV for a given combination of height and gender, a CI for the prediction can be interpreted as a CI for the mean FEV, given the predictors. These can be computed using the optional argument interval in the predict() function, as done below (we use head() to limit the output to the first six cases in dns): predict(model1, interval = &quot;confidence&quot;) %&gt;% head() fit lwr upr 1 0.6287320 0.5340036 0.7234604 2 0.8833903 0.7985886 0.9681921 3 0.8833903 0.7985886 0.9681921 4 0.8833903 0.7985886 0.9681921 5 0.9852537 0.9042798 1.0662275 6 0.9852537 0.9042798 1.0662275 The result of the previous function call is a matrix, having as many rows as dns and three columns: fit (the predicted value), and lwrand upr corresponding to the lower and upper limits of the 95% CI for the prediction. These can be used to plot the confidence bands of the model equation, as done in figure 1.4. Note in the code below the sub-setting of the matrix produced by predict(), using [,1], [,2], and [,3] to get the first, second or third column of the matrix, respectively. gf_point(fev ~ height | gender, col = ~ gender, data =dns, alpha = 0.2) %&gt;% gf_line(predict(model1, interval = &quot;confidence&quot;)[,1] ~ height) %&gt;% gf_line(predict(model1, interval = &quot;confidence&quot;)[,2] ~ height, linetype = 2) %&gt;% gf_line(predict(model1, interval = &quot;confidence&quot;)[,3] ~ height, linetype = 2) Figure 1.4: Graphical representation of model 1 (solid lines) and 95% confidence bands (dashed lines) The confidence bands (dashed lines) in figure 1.4 mean that, in the population, the model could be any line we can draw within these limits. Note that the bands are not straight lines parallel to the estimated model (solid line), but are curved, so that the CI is wider for extremes values of height (such as 120 or 180 cm) than they are for values close to the mean of height (such as 150 cm). 1.3.3 Tests on the model coefficients Suppose we are doubtful about the relation between one of the explanatory variables (\\(X\\)) and the predicted variable \\(Y\\). For instance, we may wonder if gender is really related to fev. If gender was unrelated to the forced expiratory volume, then the slope of gender would be equal to zero in the population equation (meaning that gender has no effect on the FEV, or is unrelated to FEV). Therefore, we would like to conduct a significance test with the following hypotheses: \\[H_0: \\qquad \\beta_{genderM} = 0\\] \\[H_1: \\qquad \\beta_{genderM} \\ne 0\\] Such type of tests, sometimes called Wald tests, can be produced with function summary() applied to the model object model1: summary(model1) Call: lm(formula = fev ~ height + gender, data = dns) Residuals: Min 1Q Median 3Q Max -1.6550 -0.2498 -0.0003 0.2302 2.1046 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -5.330273 0.183930 -28.980 &lt;2e-16 *** height 0.050932 0.001204 42.301 &lt;2e-16 *** genderM 0.105677 0.034657 3.049 0.0024 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.4138 on 586 degrees of freedom Multiple R-squared: 0.764, Adjusted R-squared: 0.7632 F-statistic: 948.8 on 2 and 586 DF, p-value: &lt; 2.2e-16 The first part of the output (Residuals) shows summary statistics for the residuals of the model. The minimum residual is -1.655 liters, the maximum is 2.1046 liters, and the median is very close to zero. The mean of the residuals is not reported because it is always exactly zero (this is a property of GLS models). The Coefficients part of the output shows the estimates of the model coefficients (first column Estimate), their standard error (Std. Error), a t-statistic (t value) and the p value (Pr(&gt;|t|)). When the p value is too small, the null hypothesis stated above is rejected. In this case, all coefficients show small p values and therefore we can conclude that they are all different from zero in the population equation. In other words, for coefficients other than the intercept, a significant result in this test is interpreted as evidence of a linear relation of FEV with the corresponding explanatory variable. In this case, the Wald tests provide evidence that both height and gender are related to FEV. Last, the output provides an estimate for the standard deviation of the residuals \\(\\sigma\\) (Residual standard error), some measures of how well the model fits the data (Multiple R-squared and Adjusted R-squared), and a test (F-statistic and p-value) of the null hypothesis that all \\(\\beta\\) coefficients are zero in the population regression equation, i.e., that all explanatory variables are linearly independent of the \\(y\\) variable. 1.4 Goodness-of-fit In our sample data, the FEV values (\\(Y\\)) range from 0.791 to 5.793 liters, with mean 2.566 liters. If we want to predict the FEV value for a particular individual and we have no information on his or her height and gender, our best guess would be the mean value of FEV in the whole sample, 2.566 liters. The error of such a prediction would be the difference between the observed FEV for this individual (\\(Y\\)) an the mean of FEV (\\(\\bar{Y}\\)), that is, \\(Y - \\bar{Y}\\). However, if we know the height and the gender of this individual, we can get a better prediction using model1 (\\(\\hat{Y}\\) = -5.33027 + 0.05093 height + 0.10568 genderM), reducing the prediction error to \\(Y - \\hat{Y}\\). In fact, the error of the initial prediction based on the sample mean (\\(Y - \\bar{Y}\\)) can be decomposed in two parts, as follows: \\[\\begin{equation} Y - \\bar{Y} = (Y - \\hat{Y}) + (\\hat{Y} - \\bar{Y}) \\tag{1.2} \\end{equation}\\] \\((Y - \\hat{Y})\\) is the residual of model1, that is, the prediction error when using model1 to get a better prediction \\(\\hat{Y}\\). \\((\\hat{Y} - \\bar{Y})\\) is the part of the error in our initial prediction that can be explained by model1 (i.e., by the height and the gender of the individual). This decomposition has been represented in figure 1.5 for a couple of cases. The black solid lines are predictions made by model1. The black dashed lines indicate the overall mean of FEV in the sample. Blue segments indicate the deviation from the overall mean that are explained by the model, and red segments indicate the residuals, that is, the part of deviation from the overall mean that are not explained by the model. Figure 1.5: Graphical representation of the decomposition of deviations from overall mean of FEV according to model 1 It can be shown that the equality of equation (1.2) holds after squaring the three differences and summing over all the (\\(n\\)) individuals, that is \\[\\begin{equation} \\sum_{i=1}^{n} (Y - \\bar{Y})^2 = \\sum_{i=1}^{n}(Y - \\hat{Y})^2 + \\sum_{i=1}^{n}(\\hat{Y} - \\bar{Y})^2 \\tag{1.3} \\end{equation}\\] The three terms in equation (1.3) are called sums of squares (or sometimes, variation), and measure (from left to right): the total variation of \\(Y\\) around its mean \\(\\bar{Y}\\), the variation of the residuals, and the variation of the predictions \\(\\hat{Y}\\) around the mean \\(\\bar{Y}\\). Equation (1.3) shows that the total sum of squares can be decomposed in two parts: the residual sum of squares, and the variation of the model predictions. Let’s verify this for model1: ## sum of squares of ss_total &lt;- sum((dns$fev - mean(dns$fev))^2) # variation of FEV around its mean ss_resid &lt;- sum(resid(model1)^2) # variation of residuals ss_model &lt;- sum( (predict(model1) - mean(dns$fev))^2 ) # variation of predictions ss_total [1] 425.3515 ss_resid [1] 100.3642 ss_model [1] 324.9872 ss_resid + ss_model == ss_total [1] TRUE Clearly, the greater the variation of the predictions (blue segments in figure 1.5) and the smaller the variation of the residuals (red segments), the better the model will be. Then, a natural measure of how well a model fits the data will be given by the proportion of the total variation that is explained by the model, that is \\[R^2 = \\frac{\\sum_{i=1}^{n}(\\hat{Y} - \\bar{Y})^2}{\\sum_{i=1}^{n} (Y - \\bar{Y})^2}\\] This quantity, called coefficient of determination R-squared, measures how good a model is: the higher the \\(R^2\\) value, the better a model fits the data (or predicts \\(Y\\)). Since all terms in equation (1.3) are necessarily non-negative (because of the squares), and the top of the previous formula is part of the bottom, the theoretical range of \\(R^2\\) is 0 to 1. A value of 0 would imply that the model explains no variation at all. A value of 1 would imply that the model explains all the variation (and there is no residual variation), in which case the model would fit the data perfectly. It is easy to verify that the previous formula for \\(R^2\\) gives the same result given by summary(model1): ss_model / ss_total # R-squared computed from sums of squares [1] 0.764044 summary(model1)$r.squared # R-squared as reported by summary(model1) [1] 0.764044 Thus, model1 explains 76.4 % of the total variation of FEV values. Consequently, the residual variation is 23.6 % of the total variation of FEV. Figure 1.6 shows the centered distributions1 of observed and predicted FEV values, and of the residuals. Figure 1.6: centered distribution of observed and predicted FEV, and residuals Although \\(R^2\\) is a goodness-of-fit measure with an interesting interpreteation (i.e., the proportion of variance of the outcome variable that is explained by the model), it has a limitation when used to compare different models. This limitation is due to the fact that \\(R^2\\) will increase as we add explanatory variables to a model, even if some of these variables do not improve much its predictive capacity. Therefore, when comparing two models with a different number of predictors, the more complex model will always have a higher \\(R^2\\) value, and might be judged to be better than simpler models. However, simple models (or parsimonious models, as they are sometimes called) are in general preferable to complex models, particularly when the later includes some predictors with no predictive capacity. To avoid this problem, a version of \\(R^2\\) that penalizes model complexity is given by a measure called adjusted \\(R^2\\), which is computed as: \\[R^2_{adj} = 1-\\frac{(1-R^2)(n-1)}{n-k-1}\\] where \\(n\\) is the number of observations and \\(k\\) is the number of coefficients in the model, excluding the intercept. As noted in the previous section, the value of both \\(R^2\\) and \\(R^2_{adj}\\) are shown at the end of the output provided by summary(). \\(R^2_{adj}\\) provides a measure better than \\(R^2\\) to compare models with a different number of predictors. \\(R^2_{adj}\\) may be actualy lower if the additional predictors of the more complex model have little capacity of improving predictions. 1.5 Assessing assumptions The validity of the inferential analyses discussed in section 1.3 depend on the following assumptions: The relation of \\(Y\\) and \\(X\\) variables is as specified by the model, i.e., the model is appropriate. Observations are independent from each other. The prediction errors follow a normal distribution with constant variance. The last two assumptions are sometimes expressed by saying that errors are independent and identically distributed (iid) random variables following a normal distribution with constant variance, which is concisely expressed as \\(\\quad \\epsilon \\sim N(0, \\sigma)\\). The independence of observations is generally met when each observation corresponds to a different individual, which is the case in the dns dataset. However, this assumption would be violated if some individual(s) contributed with more than one observation (i.e, when two or more points in a scatterplot correspond to the same individual). The condition of independent observations is sometimes expressed by saying that the error terms of different observations are uncorrelated, i.e., \\(Cov(\\epsilon_i, \\epsilon_j) = 0\\) for all \\(i \\ne j\\). The remaining assumptions can be verified by inspecting some plots of the residuals that can be easily produced with the base R function plot() applied to the model object, and a further argument to indicate the type of plot we want (out of six plot types; see ?plot() for more details). A couple of such plots are produced below for model1: a residual vs predicted (or fitted) values, and a normal quantile-quantile plot of the residuals. Because these plots are created with the base R plotting system, the par() function is used previously to set two graphic slots and the plot margins. # to set two slots (side by side) in the graphic output, and the plot margins par(mfrow = c(1,2), mar = c(4,7,2,2)) plot(model1, 1) # plot 1: residuals vs predicted values plot(model1, 2) # plot 2: Normal QQ plot of residuals Figure 1.7: Diagnostic plots for model1 When the model assumptions hold, a zero-centered horizontal band (or ellipse) should be seen in the Residual vs Fitted plot of figure 1.7 (left), with about the same vertical variability for all fitted values. In this case we see a slightly U-shaped pattern (highlighted by the red line) instead of a horizontal band, which means that the relation of fev and height is not linear. In addition, the vertical variability of the residuals increases from left to right, suggesting that their variance is not constant, a phenomenon called heteroscedasticity. In fact, both the non-linearity and the heteroscedasticity are already visible in the scatterplot of figure 1.1 (center), but the residual vs fitted plot makes them even more evident. The Normal QQ plot 1.7 (right) shows a pretty good approximation to the normal distribution (most points are over the dashed line representing a perfect normal distribution), though there is a slight deviation in the tails of the distribution, where some outliers are identified by the row number in dataframe dns. Non-linearities and heteroscedasticity are common phenomena when analyzing real data. In the next sections we see how to cope with them and fit better models. 1.5.1 Fixing non-linearity: polynomials There are several ways we could try to address a non-linear relationship of \\(Y\\) with an explanatory variable \\(X\\) . One such way is to use polynomials to accommodate the non-linearity. Let’s try to fit a model with a linear and a quadratic term for height, by using function poly(). This function builds a polynomial for the variable indicated as first argument, and the degree of the polynomial as second argument. Here, we fit a quadratic function (a second degree polynomial) for height and then show its graphical representation by plotting predicted values over the scatterplot: model2 &lt;- lm(fev ~ poly(height,2) + gender, data = dns) gf_point(fev ~ height, col = ~ gender, data =dns, alpha = 0.3) %&gt;% gf_line(predict(model2) ~ height, col = ~ gender, data = dns) Figure 1.8: Graphical representation of model2 Figure 1.8 shows that a second degree polynomial on height follows more closely the change of FEV as height increases. The estimates of the model coefficients are now: model2 Call: lm(formula = fev ~ poly(height, 2) + gender, data = dns) Coefficients: (Intercept) poly(height, 2)1 poly(height, 2)2 genderM 2.53928 17.87793 2.87018 0.05104 Therefore, the estimated equation is predicted fev = 2.53928 + 17.87793 height + 2.87018 height^2 + 0.05104 genderM By inspecting the diagnostic plots for model2 we see we have fixed the non-linearity problem, but heteroscedasticity persists: par(mfrow = c(1,2), mar = c(4,7,2,2)) plot(model2, 1) plot(model2, 2) Figure 1.9: Diagnostic plots for model 2 1.5.2 Fixing heteroscedasticity Heteroscedasticity is sometimes fixed using a logarithmic transformation of the \\(Y\\) variable. Let’s see what happens if we plot the logarithm of FEV against height: gf_point(log(fev) ~ height, col = ~ gender, data =dns, alpha = 0.3) Figure 1.10: Scatterplot of log(FEV) by height and gender In figure 1.10, the relation of log(fev)and height looks linear, with pretty constant variability of log(fev) values across height values. So, by taking logs of FEV, we got rid of both the non-linearity and heteroscedasticity. Let’s then fit a third model using log(fev) instead of fev as dependent variable, and see what are the estimates of the model coefficients: model3 &lt;- lm(log(fev) ~ height + gender, data = dns) model3 Call: lm(formula = log(fev) ~ height + gender, data = dns) Coefficients: (Intercept) height genderM -2.2771 0.0205 0.0168 The estimated equation is now: predicted log(fev) = -2.2771 + 0.0205 height + 0.0168 genderM Diagnostic plots (figure 1.11 look better now: the residual vs fitted values shows a horizontal ellipse with no hint of heteroscedasticity, but the normal QQ plot shows just a couple of outliers in the lower tail. par(mfrow = c(1,2), mar = c(4,7,2,2)) plot(model3, 1) plot(model3, 2) Figure 1.11: Diagnostic plots of model 3 1.5.3 Influence measures Outliers may influence the estimates of the model parameters (i.e., distort these estimates). Weather or not they do it in a non-negligible way depends on how many they are, how far they are, and the sample size; but it may be difficult to judge their influence from the graphics of figure 1.11. To judge this, a measure of influence called Cook’s distance is useful. The Cook’s distance \\(D_i\\), which is computed for each observation (\\(i = 1, 2, ..n\\)), is a (normalized) measure of the overall change in the predicted values that would result from removing this observation. \\[D_i = \\frac{\\sum_{j=1}^{n} (\\hat{Y}_j - \\hat{Y}_{j(i)})^2}{k \\; MSE}\\] where, \\(\\hat{Y}_j\\) is the predicted value for observation \\(j\\) \\(\\hat{Y}_{j(i)}\\) is the predicted value for observation \\(j\\) after removing observation \\(i\\) \\(k\\) is the number of coefficients in the model, and \\(MSE\\) is the mean squared error (the mean of the squared residuals). Cook’s distances can be inspected in a further diagnostic plot we can get with plot(), passing 4 as second argument: plot(model3, 4) Figure 1.12: Cook’s distances by observation index As a rule of thumb, outlying observations will have little influence if the Cook’s distance is below 0.5 (or even below 1). Therefore, no worries in this case, since the highest value is about 0.05 (for observation 111). 1.6 Probability intervals (or prediction intervals) In section 1.3.2 we saw how to get CIs for the model predictions, which refer to the expected or mean values \\(\\hat{Y}\\) for cases with particular values of the explanatory variables. But suppose we now want to compute a probability interval, an interval that will include individual \\(Y\\) values with a given probability. This type of interval can be also computed with function predict(), but specifying the argument interval = \"prediction\" as done below (we use head() to limit the output to the first six cases in dns): predict(model3, interval = &quot;prediction&quot;) %&gt;% head() fit lwr upr 1 0.1219614 -0.17245402 0.4163768 2 0.2244847 -0.06953864 0.5185081 3 0.2244847 -0.06953864 0.5185081 4 0.2244847 -0.06953864 0.5185081 5 0.2654941 -0.02838958 0.5593777 6 0.2654941 -0.02838958 0.5593777 The output shows the predictions (fit) and lower (lwr) and upper (upr) limits of 95% probability intervals. By default, predict()computes 95% probability or confidence intervals, but this can be changed with its optional argument level. Below we plot the 95% probability bands and also the 95% CI bands for model3 to see how different they are: probability bands are much wider than confidence bands. gf_point(log(fev) ~ height | gender, col = ~ gender, data =dns, alpha = 0.2) %&gt;% gf_line(predict(model3, interval = &quot;prediction&quot;)[,1] ~ height) %&gt;% gf_line(predict(model3, interval = &quot;prediction&quot;)[,2] ~ height, linetype = 2) %&gt;% gf_line(predict(model3, interval = &quot;prediction&quot;)[,3] ~ height, linetype = 2) %&gt;% gf_line(predict(model3, interval = &quot;confidence&quot;)[,2] ~ height, linetype = 2, color = &quot;black&quot;) %&gt;% gf_line(predict(model3, interval = &quot;confidence&quot;)[,3] ~ height, linetype = 2, color = &quot;black&quot;) Figure 1.13: Graphical representation of model 3 (solid lines), 95% CI bands (black dashed lines) and 95% probability bands (colored dashed lines) Because model3 was fitted on the log of FEV, predictions, confidence intervals and probability intervals computed from this model are log-transformed values of FEV (see the vertical axis of figure 1.13). However, the log transformation can be reverted by exponentiating the results (i.e., the predictions, their CI’s and predictiony intervals): gf_point(fev ~ height | gender, col = ~ gender, data =dns, alpha = 0.2) %&gt;% gf_line(exp(predict(model3, interval = &quot;prediction&quot;)[,1]) ~ height) %&gt;% gf_line(exp(predict(model3, interval = &quot;prediction&quot;)[,2]) ~ height, linetype = 2) %&gt;% gf_line(exp(predict(model3, interval = &quot;prediction&quot;)[,3]) ~ height, linetype = 2) %&gt;% gf_line(exp(predict(model3, interval = &quot;confidence&quot;)[,2]) ~ height, linetype = 2, color = &quot;black&quot;) %&gt;% gf_line(exp(predict(model3, interval = &quot;confidence&quot;)[,3]) ~ height, linetype = 2, color = &quot;black&quot;) Figure 1.14: Transforming back the results to the original FEV scale The 95% probability intervals for individual FEV values shown in figure 1.14 could be used as reference normal ranges for FEV, given the height and gender of an individual (as we supposed was the goal of the analysis in section 1.1). 1.7 Models with two continuous predictors The models fitted in previous sections were all based on height and gender, which are quantitative and categorical variables, respectively. That is why the graphical representation of these models was a couple of lines, one for each gender, describing the relation of FEV and height. Let’s now fit a model with two quantitative predictors, such as height and age: model4 &lt;- lm(log(fev) ~ height + age, data = dns) model4 Call: lm(formula = log(fev) ~ height + age, data = dns) Coefficients: (Intercept) height age -1.93120 0.01677 0.02493 Therefore, the estimated equation is: predicted fev = -1.93120 + 0.01677 height + 0.02493 age When a model is based on two quantitative explanatory variables, the equation corresponds to a plane. Figure 1.15 shows the regression plane of model4. This plane cuts the \\(Y\\) axis at the intercept (-1.93120), and is tilted according to the slopes of height and age (in the direction of their respective axes). Figure 1.15: Graphical representation of model 4: regression plane If a model has more than two quantitative predictors, the plane generalizes to a hyperplane that cannot be represented graphically in a 2D screen. But let’s see what happens if we addition a categorical variable like gender to model4: model5 &lt;- lm(log(fev) ~ height + age + gender, data = dns) model5 Call: lm(formula = log(fev) ~ height + age + gender, data = dns) Coefficients: (Intercept) height age genderM -1.90378 0.01642 0.02609 0.02840 Therefore, the estimated equation is: predicted fev = -1.90378 + 0.01642 height+ 0.02609 age + 0.02840 genderM. Now model5 are two parallel regression planes, as shown in figure 1.16. While the two planes may look the same, they are actually different. The intercept for the plane of females is -1.90378, while that of males is -1.875385. Guess why? Figure 1.16: Graphical representation of model 5: parallel regression planes for males an females 1.8 Comparing models In previous sections we fitted three different models for log(fev): model3, model4 and model5. A first step in comparing these three models is to look at their \\(R^2_{adj}\\) values. We can easily pick the value of \\(R^2_{adj}\\) from the summary of a model, since summary() produces a list and one of its elements is precisely the \\(R^2_{adj}\\) statistic, identified as adj.r.squared: summary(model3) %&gt;% names() # elements of summary() result? [1] &quot;call&quot; &quot;terms&quot; &quot;residuals&quot; &quot;coefficients&quot; [5] &quot;aliased&quot; &quot;sigma&quot; &quot;df&quot; &quot;r.squared&quot; [9] &quot;adj.r.squared&quot; &quot;fstatistic&quot; &quot;cov.unscaled&quot; Here we pick the adj.r.squared element of each model summary: summary(model3)$adj.r.squared [1] 0.7984583 summary(model4)$adj.r.squared [1] 0.81268 summary(model5)$adj.r.squared [1] 0.8141139 According to \\(R^2_{adj}\\), model5 is better. However, particularly when the improvement in \\(R^2_{adj}\\) is small, we may wonder if it is significantly better. This can be investigated with function anova(), by passing two (or more) models as arguments, provided they are nested models. Two models are nested if one of them is contained in the other. Here we compare model4 and model5: anova(model4, model5) Analysis of Variance Table Model 1: log(fev) ~ height + age Model 2: log(fev) ~ height + age + gender Res.Df RSS Df Sum of Sq F Pr(&gt;F) 1 586 12.075 2 585 11.962 1 0.11288 5.5202 0.01913 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The result shows the residual sum of squares (RSS) and the residual degrees of freedom (Res.Df) for each model (the residual degrees of freedom of a model is the sample size minus the number of parameters in the model). Then, for the second model in the output, the change in both degrees of freedom (Df) and RSS (Sum of Sq) with respect to the first model are shown, as well as the result of an F-test (F) assessing the significance (Pr(&gt;F)) in the reduction of the RSS. In this case, the low p value indicates a significant reduction in the RSS of the second model (model 5) as compared to the first model (model4). Therefore, we can conclude that model5fits the data significantly better than model4. 1.9 Confounding Suppose we now want to investigate the effect of smoking on the FEV. Figure 1.17 (left) shows the boxplot of fev by smoke in dataframe d. Surprisingly enough, smokers tend to show higher FEV values than non-smokers, which is counter intuitive. plot1 &lt;- gf_boxplot(fev ~ smoke, data = d) + coord_flip() plot2 &lt;- gf_boxplot(age ~ smoke, data = d) + coord_flip() plot1 + plot2 Figure 1.17: FEV and age in smokers and non-smokers However, it is the case that smokers are older than non-smokers as shown in figure 1.17 (right), and this might be the reason why, when comparing the fev values in smokers and non-smokers without taking age into account, we see higher FEV values in non-smokers. This can be verified by fitting a couple of models for fev, one of them including only smoke as predictor, and the other including both smoke and age: lm(fev ~ smoke, data =d) Call: lm(formula = fev ~ smoke, data = d) Coefficients: (Intercept) smokeyes 2.5661 0.7107 lm(fev ~ smoke + age, data =d) Call: lm(formula = fev ~ smoke + age, data = d) Coefficients: (Intercept) smokeyes age 0.3674 -0.2090 0.2306 In the first model, the estimated effect of smoking is 0.7107, suggesting that the expected FEV is 0.7107 liters higher in smokers than in non-smokers. However, in the second model the expected FEV in smokers given the age, is 0.2090 liters lower in non-smokers than in smokers. The change in the estimated effect of smoking from the first to the second model reflects the fact that, in the former, the effect of age is not taken into account, and because age is related to smoking, its effect is confounded with that of smoking. In the second model, the effect of smoking is adjusted by age, or estimated after partialling out the effect of age. As seen in this example, when we want to assess the effect of a variable \\(X_1\\) on an outcome variable \\(Y\\), modeling provides a way to address potential confounding by including the potential confounder(s) as additional explanatory variable(s) in the model. If the effect of \\(X_1\\) does not changes appreciably, there is no confounding. However, an appreciable change in the effect of \\(X_1\\) is an indication of confounding. 1.10 Interaction (effect modification) The National Health and Nutrition Examination Survey (NHANES) is a program of studies designed to assess the health and nutritional status of adults and children in the United States. The survey examines a nationally representative sample of about 5,000 persons each year. The dataset calcium.RData is an extract of the 2009-2010 NHANES survey containing complete data of calcium concentration in blood (mg/dl), gender, age, and vitamin D (nmol/l) for adults older than 25 years. Download calcium.RData Let’s get the data file with load(), and explore how calcium concentration values relate to age and gender. load(&quot;data/calcium.RData&quot;) gf_point(calcium ~ age | gender, data = calcium, color = ~gender, alpha = 0.2) Figure 1.18: Calcium concentration (mg/dl) by age and gender Figure 1.18 shows a very slight decrease of calcium concentration with age in males, but a slight increase in females. Fitting a linear model with age and gender as explanatory variables implies to fit two lines, one for each gender, having different intercepts but the same slope, so that it cannot accommodate what we observe in this plot. To allow for different slopes, we need to add an interaction term to the model. An interaction term is a product of two explanatory variables, such as age and gender in this case. In general, a model with a term of interaction between two explanatory variables \\(X_1\\) and \\(X_2\\) will be of the form: \\[Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_{12} X_1 X_2 + \\epsilon\\] Suppose \\(X_1\\) is a continuous variable (like age), and \\(X_2\\) is an indicator for a dichotomous variable (like gederfemale, coded as 0 for males and 1 for females). Then, the model simplifies to the following equations for males and females: For males: \\[Y \\quad = \\quad \\beta_0 + \\beta_1 X_1 + \\beta_2 \\times 0 + \\beta_{12} X_1 \\times 0 + \\epsilon \\quad = \\quad\\beta_0 + \\beta_1 X_1 + \\epsilon\\] For females: \\[Y \\quad = \\quad \\beta_0 + \\beta_1 X_1 + \\beta_2 \\times 1 + \\beta_{12} X_1 \\times 1 + \\epsilon \\quad = \\quad (\\beta_0 + \\beta_2) + (\\beta_1 + \\beta_{12}) X_1 + \\epsilon \\] Both equations above are straight lines, but they have a different intercept and a different slope. Interaction terms can be specified in function lm() in two different ways. One of them is to specify the two explanatory variables as usual (X1 + X2), and then add an additional term of the form X1:X2. The following fits a model with an interaction between age and gender using this syntax (note the colon between ageand gender in the last term of the formula): m1 &lt;- lm(calcium ~ age + gender + age:gender, data = calcium) Alternatively, we can specify just the two explanatory variables, but using an asterisk instead of a plus sign between them (X1*X2), as in the following code (note the asterisk between age and gender): m1 &lt;- lm(calcium ~ age * gender, data = calcium) In both cases we are fitting the same model, with main effects for age and gender, plus a term of interaction between them. Here we summarize the fit of this model: summary(m1) Call: lm(formula = calcium ~ age * gender, data = calcium) Residuals: Min 1Q Median 3Q Max -1.9930 -0.2389 -0.0116 0.2116 2.6834 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 9.5726854 0.0253009 378.354 &lt; 2e-16 *** age -0.0024783 0.0004569 -5.424 6.1e-08 *** genderfemale -0.4282551 0.0348558 -12.286 &lt; 2e-16 *** age:genderfemale 0.0076006 0.0006338 11.993 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.363 on 5091 degrees of freedom Multiple R-squared: 0.03305, Adjusted R-squared: 0.03248 F-statistic: 58 on 3 and 5091 DF, p-value: &lt; 2.2e-16 The Wald test for the interaction term age:genderfemale produces a very small p value, providing evidence of an interaction between age and gender. The estimated equation is: predicted Ca = 9.5726854 -0.0024783 age -0.4282551 genderfemale + 0.0076006 age x genderfemale which for males (genderfemale = 0) it simplifies to: predicted Ca = 9.5726854 -0.0024783 age and for females (genderfemale = 1), it simplifies to: predicted Y = (9.5726854 -0.4282551) + (0.0076006 - 0.0024784) age = 9.14443 + 0.0051222 age Note that the slope is negative for males, but positive for females. A graphical representation of this model is shown in figure 1.19. gf_point(calcium ~ age | gender, data = calcium, color = ~gender, alpha = 0.1) %&gt;% gf_line(predict(m1) ~ age | gender, color = &quot;black&quot;) Figure 1.19: Graphical representation of model m1 In the example we have considered, there is an interaction of a continuous and a categorical variable (age and gender, respectively). However, interactions may arise between any type of variables, like two continuous variables, or two categorical variables. In any case, the way to fit and test for interaction terms is exactly the same. Sometimes, when there is an interaction of two explanatory variables, the term effect modifier is applied to one of these variables. For instance, we could say that gender is a modifier of the effect of age on the calcium concentration, since the coefficient of age (that is, the effect of age) is different in males and females. Resources Elements of statistical learning, by T. Hastie, R. Tibshirani and J. Friedman, is a very good book on both classical and modern modeling methods, such as random forest, support vector machines or neural networks. Regression modeling strategies, by F.Harrell, is another very good book on modeling (with R). Be aware of common problems you may find when fitting a GLM (or othe types of multivariate model): Be aware of heteroscedasticity and how to deal with it. Be aware of what is colinearity, how to detect it, and how to deal with it. Be aware of autocorrelated errors and how to deal with them. Be aware of how to detect and deal with outliers in regression. Be aware of other pitfalls such as overfitting and extrapolation. For influence measures other than the Cook’s distance, see this article, and see also the help of influence.measures() in R (?influence.measures). When there are many potential predictor variables, the number of possible models can be very large, and it is not feasible to fit and assess them one at a time. Read this introduction to automated model selection methods. A post on different types of regression analysis you may want to know about. Exercises Figure 1.2 shows the graphical representation of model 1, in which fev is expressed as a linear function of height and gender: What is the model equation? Why do you think the graphical representation of this model are two parallel straight lines? Hint: simplify the model equation for a male (genderM = 1) and for a female (genderM = 0). Use the simplified equations to predict the FEV expected for a boy with body height = 170 cm, and for a girl having the same height. What is the difference between both predictions? Compare your predictions with those obtained with predict(). Plot the 95% probability intervals for model1 on fev and for model3 on log(fev). In which of the two models the probability intervals seem to work better (i.e., include about 95% of the cases, for any given combination of height and gender)? Regarding model 5, in which log(fev) is expressed as a linear function of height, age and gender, why do you think the graphical representation of this model in figure 1.15 are two parallel planes? Hint: simplify the model equation for a male (genderM = 1) and for a female (genderM = 0). Produce diagnostic plots for modle5. Do you think that the model assumptions are reasonable? Using dataframe d (including smokers), fit a model for log(fev) with height, age, gender and smoke as predictors, and answer the following questions: According to Wald tests, are all predictor variables necessary? What is the proportion of variation of log(fev) explained by this model? Compare this model to model5 fitted on all cases in d. Which one best fits the data? Is there a significant improvement in the model fit by adding smoke to model5? Dataframe Births78 in the mosaic package contains the number of births registered in the USA in 1978. Inspect a scatterplot of births by date. Taking into account that each dot is a day, what do you think is the reason for the two-wave pattern? (Hint: are the two waves equally crowded?) Compute a new variable day taking values “Work”, “Sat” or “Sun” (it should be a factor, with levels defined in this order), and repeat the previous plot using color for day. Is it now clear what is the reason for the two waves? There are a few “Work” days behaving much like weekends. Can you anticipate an explanation for this? Fit a first model (m1) for births using day and a polynomial of degree 5 for month. Produce a graphical representation of this model. Why do you think it takes the form of a step function? Fit a second model (m2) similar to the previous one, but using day_of_year instead of month; produce its graphical representation and compare it to the previous one. Which one best fits the data? Run the following code to create a new variable identifying working days that were bank holidays in 1978, fit a third model (m3) adding this variable to m2, and compare them. Is there a significant improvement in fit after adding variable holiday to the predictors? h &lt;- as.Date(c(&quot;1978-01-02&quot;, &quot;1978-02-20&quot;, &quot;1978-05-29&quot;, &quot;1978-07-04&quot;, &quot;1978-09-04&quot;, &quot;1978-11-11&quot;, &quot;1978-11-23&quot;, &quot;1978-12-25&quot;)) d &lt;- d %&gt;% mutate(holiday = ifelse(date %in% h &amp; day == &quot;Work&quot;, &quot;Yes&quot;, &quot;No&quot;)) What is the proportion of the number of births variance explained by model m3? Assess the assumptions of model m3 by producing diagnostic plots. Do you think the assumptions are reasonable? Do you think the assumption of independence of observations is reasonable? A centered distribution is what results from subtracting the mean from all its values. For example, \\(Y-\\bar{Y}\\) is the centered distribution of \\(Y\\).↩︎ "],["the-logistic-regression-model-lrm.html", "2 The logistic regression model (LRM) 2.1 Logit transformation 2.2 Fitting a LRM 2.3 Interpretation of model coefficients 2.4 Inference on the model coefficients 2.5 Assessment of fit 2.6 Model predictions and classification 2.7 Comparing models 2.8 Confounding 2.9 Interaction (effect modification) 2.10 Model diagnostics Resources Exercises", " 2 The logistic regression model (LRM) The burn1000 dataset in the aplore3 package has data on 1000 cases of burns, including the hospital discharge status (Dead or Alive), demographic variables, the total burn surface area (as percentage of body surface area), and weather or not the burn involved inhalation injury or flames (see ?burn1000). After loading the required packages, we rename the outcome variable, save the result as d, and get a summary of selected variables: library(tidyverse) library(aplore3) d &lt;- burn1000 %&gt;% rename(outcome = death) select(d, -id, -facility, - race) %&gt;% summary() outcome age gender tbsa inh_inj flame Alive:850 Min. : 0.10 Female:295 Min. : 0.10 No :878 No :471 Dead :150 1st Qu.:10.85 Male :705 1st Qu.: 2.50 Yes:122 Yes:529 Median :31.95 Median : 6.00 Mean :33.29 Mean :13.54 3rd Qu.:51.23 3rd Qu.:16.00 Max. :89.70 Max. :98.00 The previous output shows that most patients survived, age ranged from less than one to almost 90 years and males predominate; relatively few burns involved inhalation injury but almost half of them involve flame; and the total burn surface area varied widely, ranging from less than 1% to 98%. Suppose we want to predict the outcome “Dead” from the total burn surface area. We could do it by coding the outcome as an indicator (0 for “Alive”, 1 for “Death”) and fitting a straight line (GLM), as done in figure 2.1 (left). The outcome can take values 0 or 1 only, but we could interpret the predictions of the linear model for any given tbsa as outcome probabilities. However, for extreme values of tbsa like 1% or 90%, the linear model predicts a value out of the allowed range for a probability: less than 0 for values of tbsa close to 0, and more than 1 for values of tbsa close to 1. Clearly, the linear model in not appropriate. Figure 2.1: Linear and logistic functions to model the probability of death from the total body surface area To circumvent the problem of getting predicted probabilities out of the allowed 0 to 1 range, we should use an asymptotic function that never crosses the 0 and 1 boundaries for a probability. One such function is the logistic function shown in figure 2.1 (right). This function is: \\[\\pi = \\frac{e^{\\beta_0 + \\beta_1 X}}{1 \\enspace + \\enspace e^{\\beta_0 + \\beta_1 X}}\\] where \\(\\pi\\) denotes the probability of observing the event of interest. Note that the event of interest is one of the levels of a binary variable, (such as outcome = \"Death\"). Then, a more explicit notation for this probability would be \\(\\pi(Death)\\), but for the sake of simplicity and the clarity of formulas, we use simply \\(\\pi\\). The logistic function can be used as well with more than one explanatory, variable. A logistic function with \\(p&gt;1\\) explanatory variables is: \\[\\begin{equation} \\pi = \\frac{e^{\\beta_0 + \\beta_1 X + \\beta_2 X + ... + \\beta_p}}{1 \\enspace + \\enspace e^{\\beta_0 + \\beta_1 X + \\beta_2 X + ... + \\beta_p}} \\tag{2.1} \\end{equation}\\] 2.1 Logit transformation The logistic function in (2.1) is a quite complex function of the explanatory variables \\(X_1, X_2,..., X_p\\). Fortunately, it can become much simpler in terms of a transformation of \\(\\pi\\) called logit or log odds, which is the natural logarithm of the odds of death. It can be proved that equation (2.1) is equivalent to: \\[\\begin{equation} ln(\\frac{\\pi}{1-\\pi}) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... \\beta_p X_p \\tag{2.2} \\end {equation}\\] The left hand side of equation (2.2) is called the logit of \\(\\pi\\), or the log-odds of \\(\\pi\\), it is linearly related to the explanatory variables, and that is why the right hand side of the equation is sometimes called the linear predictor. The LRM assumes that the relation between a probability \\(\\pi\\) and a linear predictor of explanatory variables \\(X\\) is described by the logistic function of equation (2.1); or equivalently, it assumes that the logit of this probability is described by the linear function of one or more explanatory variables of equation (2.2). Explanatory variables can be either quantitative or categorical, but categorical variables with \\(k\\) levels are entered as \\(k-1\\) binary indicators, just as in GLMs. The LRM also assumes that the binary outcome has a Bernouilli distribution of parameter \\(\\pi\\), and this implies that in any set of \\(n\\) observations having the same values of the explanatory variables, the number of cases with the event of interest follow a binomial distribution of parameters \\(\\pi\\) and \\(n\\). The coefficients of a LRM are estimated by a method called maximum likelihood (ML). This method looks for the values of the coefficients that would make the probability of the observed data as high as possible. The estimates obtained with this method are called ML estimates. ML works well in large samples, but not so well in small samples. In the case of LRMs, a rule of thumb to determine if a sample is large enough to get reliable ML estimates is to verify that we have 10 to 20 events and non-events per model coefficient. In the case of the burns dataset, we have 150 events (deaths) and 850 non-events (alive). This means that we could reliably fit models with 150/20 = 7 coefficients at most, to be on the safe side. 2.2 Fitting a LRM Suppose we want to fit a LRM to express the probability of death as a function of tbsa and flame. This can be done with function glm(), as done below. Two things should be noted: Because we want to model the probability of “Dead”, and this is a level of the outcome variable, the left hand side of the formula passed as first argument to glm() is outcome == \"Dead\"2 The second argument family = binomial is needed if we want to fit a LRM. Function glm() owes its name to the fact that it can be used to fit any type of gerneralized linear model, and LRM is just one of these types. The family argument indicates the glm() function which type of generalized lineal model we want to fit. The remaining arguments to this function are similar as those for the lm() functions we used in the previous chapter to fit GLMs. After fitting the model, we can print the estimated coefficients with coef(): m_tf &lt;- glm(outcome == &quot;Dead&quot; ~ tbsa + flame, family = binomial, data = d) coef(m_tf) (Intercept) tbsa flameYes -4.10581359 0.07811869 1.26715789 What the output shows is the estimates of the coefficients in the linear predictor. Thus, the estimated model is (rounding the coefficients to the fourth decimal): \\(ln(\\frac{\\pi}{1-\\pi})\\) = -3.3451 + 0.0854 tbsa 2.3 Interpretation of model coefficients The linear predictor of a LRM allows to compute the log odds of \\(\\pi\\), according to equation (2.2). If all \\(X\\) variables were equal to 0 in this equation, the resulting log odds would be \\(\\beta_0\\). Consequently, the intercept \\(\\beta_0\\) can be interpreted as the value of the log odds when all \\(X\\) variables 0. This will be of no particular interest if the value 0 is impossible for some \\(X\\) variable(s), which is the case in our example: tbsa = 0 cannot happen, since it would imply no burn at all. Therefore the intercept in this model has no useful interpretation. The remaining coefficients of equation (2.2) (\\(\\beta_1, \\beta_2, ..., \\beta_p\\)) quantify the change that would result in the log-odds for a unit increment in the corresponding \\(X\\) variable, while keeping constant all other \\(X\\) variables. To se this, let’s compare the log odds that will result when \\(X_1\\) takes the value \\(k\\), and when it takes the value \\(k+1\\): \\(X_1 = k: \\qquad \\qquad ln \\left( \\frac{\\pi|X_1 = k}{1-\\pi|X_1 = k} \\right) = \\beta_0 + \\beta_1 k + \\beta_2 X_2 + ... + \\beta_p X_p\\) \\(X_1 = k+1: \\qquad ln \\left( \\frac{\\pi|X_1 = k+1}{1-\\pi|X_1 = k+1} \\right) = \\beta_0 + \\beta_1 (k+1) + \\beta_2 X_2 + ... + \\beta_p X_p\\) \\(\\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad = \\beta_0 + \\beta_1 k + \\beta_1 + \\beta_2 X_2 + ... + \\beta_p X_p\\), where \\(\\pi|X_1 = k\\) is the probability of the outcome, given \\(X_1 = k\\). Comparing these two results, we see they only differ by \\(\\beta_1\\). Therefore \\(\\beta_1\\) can be written as the difference between the two log odds, and because a difference of logarithms is the logarithm of a ratio, we get: \\[\\beta1 \\quad = \\quad ln \\left( \\frac{\\pi|X_1 = k+1}{1-\\pi|X_1 = k+1} \\right) - ln \\left( \\frac{\\pi|X_1 = k}{1-\\pi|X_1 = k} \\right) \\quad = \\quad ln \\left( \\frac{\\frac{\\pi|X_1 = k+1}{1-\\pi|X_1 = k+1}}{\\frac{\\pi|X_1 = k}{1-\\pi|X_1 = k}} \\right)\\] Note that the last term of the previous equation is the logarithm of an odds ratio (OR) that compares the odds of the outcome event if \\(X_1 = k+1\\) (top) vs \\(X_1 = k\\) (bottom). So, this is the logarithm of the OR corresponding to a unit increase in variable \\(X_1\\). Therefore, the exponential of \\(\\beta_1\\) is the OR corresponding to such an increment in \\(X_1\\): \\[\\begin{equation} e^{\\beta1} \\quad = \\quad \\frac{\\frac{\\pi|X_1 = k+1}{1-\\pi|X_1 = k+1}}{\\frac{\\pi|X_1 = k}{1-\\pi|X_1 = k}} \\tag{2.3} \\end{equation}\\] Here we exponentiate the coefficients of model m_tf fitted in the previous section, using the exp() function: exp(coef(m_tf)) (Intercept) tbsa flameYes 0.01647661 1.08125099 3.55074659 The exponential of the intercept is the log odds when tbsa is zero, but as commented above this has no particular interest (since tbsa &gt; 0, by definition). The exponential of the coefficient for tbsa is the OR corresponding a unit increase in tbsa. This implies that the odds of death increases by a factor of 1.0813 (rounded to 4 decimals) for each 1% increment in tbsa. If we want to compute the OR for an increment other than 1, we just need to raise the OR we got to the desired number of units. For instance, the OR corresponding to a 10% increment in tbsa is: exp(coef(m_tf))[2]^10 tbsa 2.184063 Rounding this result to the second decimal, we may say that the odds of death increases by a factor of 2.18 for each 10% increment in tbsa. Similarly, the OR corresponding to a 20% increment in tbsa is: exp(coef(m_tf))[2]^20 tbsa 4.770132 which implies that the odds of death increases by a factor of 4.77 for each 20% increment in tbsa. 2.4 Inference on the model coefficients The equation we obtained in section 2.2 was fitted from sample data and is therefore an estimate of the population equation (i.e., the equations we would get if we could fit the model to the whole population, not just to a finite sample). We can compute 95% CIs for the model coefficients to see what are likely values of these coefficients in the population; we can also produce Wald tests to assess the null hypothesis that a specific coefficient is zero in the population. In both cases, the functions we need to use are the same as those we used for a GLM. 2.4.1 Confidence intervals (CI) for the model coefficients Confidence intervals for the coefficients of a LRM can be obtained with function confint(): confint(m_tf) 2.5 % 97.5 % (Intercept) -4.69616358 -3.5907614 tbsa 0.06518979 0.0923746 flameYes 0.71873320 1.8604831 The output shows the limits of the 95% CI for all model parameters. For instance, the 95% CI for the effect of tbsa is 0.0652 to 0.0924 (rounded to four decimals). However, this is a 95% CI for the effect of tbsa on the logit scale (equation (2.2)). To obtain a 95% CI for the OR of tbsa we need to exponentiate this result, just as we did in section 2.3 to get the point estimate of the OR: exp(confint(m_tf)) 2.5 % 97.5 % (Intercept) 0.009130237 0.02757732 tbsa 1.067361577 1.09677560 flameYes 2.051832300 6.42684078 From the output we can say that the 95% CI for the OR of tbsa ranges from 1.07 to 1.1 (rounded to the second decimal). You may find practical the following code to merge the point estimates and their correponding CI’s for the exponentiated model coefficients. We first use rbind() to merge point estimates and CI’s, and then round to the desired number of decimals: res &lt;- cbind(Estimate = exp(coef(m_tf)), exp(confint(m_tf))) %&gt;% round(2) res Estimate 2.5 % 97.5 % (Intercept) 0.02 0.01 0.03 tbsa 1.08 1.07 1.10 flameYes 3.55 2.05 6.43 If we want to compute the OR for a different increment in tbsa, say 10 years, then we need to raise the results to the power of 10. Here we do it by subsetting the second row of res, then raise it to 10, and finally round to two decimals: res[2,]^10 %&gt;% round(2) Estimate 2.5 % 97.5 % 2.16 1.97 2.59 Thus, the OR for a 10 year increase in tbsa is 2.16 [95% CI: 1.97, 2.59]. 2.4.2 Tests on the model coefficients Wald test on the model coefficients are produced with function summary(): summary(m_tf) Call: glm(formula = outcome == &quot;Dead&quot; ~ tbsa + flame, family = binomial, data = d) Deviance Residuals: Min 1Q Median 3Q Max -2.6751 -0.4115 -0.2559 -0.1916 2.8444 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -4.105814 0.280726 -14.626 &lt; 2e-16 *** tbsa 0.078119 0.006928 11.276 &lt; 2e-16 *** flameYes 1.267158 0.289756 4.373 1.22e-05 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 845.42 on 999 degrees of freedom Residual deviance: 516.68 on 997 degrees of freedom AIC: 522.68 Number of Fisher Scoring iterations: 6 The Coefficients part of the output shows the estimates of the model coefficients and the result of the Wald test for each coefficient. These asses the null hypothesis that the corresponding coefficient in the population is equal to zero (and therefore the OR = 1, since \\(e \\ ^ 0 = 1\\)). Consequently, low p values allow to reject the null hypothesis and conclude the corresponding coefficient in the population is not equal zero (and therefore the OR is not equal to 1). In this case, the Wald tests for the coefficients of tbsa and flameYes give a very low p-value, providing evidence that they are both related to the outcome (since the corresponding ORs are not equal to 1). The output of summary() also provides information on the Deviance Residuals (top of the output), Null and Residual Deviance, and AIC. (bottom). The meaning of these is explained in the next section. 2.5 Assessment of fit 2.5.1 Deviance, likelihood ratio test and AIC The deviance is a measure used to asses the fit of models estimated using maximum likelihood. However, unlike \\(R^2\\) in GLMs, the deviance is not a measure of goodness of fit, but rather it is a measure of lack of fit: the higher the deviance, the worse the fit; and the lower the deviance, the better the fit. The summary of model m_tf we got in the previous section showed two deviance values: Null deviance: the deviance of the so called null model, a model including only the intercept term, and therefore predicting the outcome as a constant. This was 845.42 on 999 degrees of freedom. The degrees of freedom is the difference between the samples size and the number of parameters estimated in a model. Because the sample size is 1000 and the null model has only one parameter (intercept), the degrees of freedom for the null model are 1000 - 1 = 999. Residual deviance: the deviance of model m_tf includig tbsa. This was 516.68 on 997 degrees of freedom (1000 - 3 estimated parameters). By including tbsa and flame as predictors, the deviance was reduced from 845.42 on 999 degrees of freedom (null model) to 516.68 on 997 degrees of freedom (current model). The change in degrees of freedom reflects the fact that we added two parameters to the null model: the coefficients for tbsa and flameYes; and this resulted in a very important reduction of the deviance, implying a much better fit. We can judge the significance of the reduction in the deviance of model m_tf using the anova() function with the argument test = \"LRT\" (for a Likelihood Ratio Test): anova(m_tf, test = &quot;LRT&quot;) Analysis of Deviance Table Model: binomial, link: logit Response: outcome == &quot;Dead&quot; Terms added sequentially (first to last) Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi) NULL 999 845.42 tbsa 1 306.763 998 538.65 &lt; 2.2e-16 *** flame 1 21.978 997 516.68 2.758e-06 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The output shows how the residual deviance changes as we add parameters to the null model. The residual deviance for the null model is 845.42 on 999 degrees of freedom (first row). By adding one coefficient for tbsa (second row), the residual deviance drops to 538.65, which is a drop of 845.42 - 538.65 = 306.77, and this deviance reduction is statistically significant according to the Likelihood Ratio Test (LRT) (Pr(&gt;Chi)), which means a significant improvement in fit. By adding one addition coefficient for flame (third row), the residual deviance drops to 516.68, for a change of 21.98), which again is a significant improvement in the fit. The residual deviance for the null model and model m_tf (last row of the output) are exactly the same values we saw at the bottom of the results provided by summary(m_tf), but here we can see that model m_tf significantly improves the fit compared to the null model, according to the LRT. Last, the AIC value appearing at the end of the summary() output, is a measure called Akaike information criterion (AIC). This is the deviance penalized for model complexity. In fact it is computed by adding twice the number of parameters to the deviance. Therefore, as it is the case with the deviance, the lower the AIC, the better the fit. The Deviance residuals at the top of the summary() output shows a brief descriptive analysis of such residuals. Deviance residuals are scaled components of the deviance, so that they provide a measure of how each observation contributes to the deviance. When a model is correct, deviance residuals follow a standard normal distribution, and therefore we expect them to have absolute values below 3. In the case of model m_tf, all deviance residuals are lower than 3 in abolute value. 2.5.2 Hosmer-Lemeshow test A quite popular way to assess the goodness of fit (GOF) of a LRM is the Hosmer-Lemeshow GOF test. In this test, observations are grouped according to the deciles of the predicted values, and expected frequencies are computed in a contingency table defined by the decile group and the observed outcome: the model probabilities are summed for cases with the event, and the complementary of model probabilities are sumed for cases without the event). Then, a goodness of fit chi-square test is used to compare expected and observed counts in this contingency table. Therefore, a low p value in this test is evidence of a bad fit. Package ResourceSelection has a function hoslem.test() implementing the Hosmer-Lemeshow GOF test. The first argument to this function is the vector of observed outcomes coded as an event indicator (0 for no event, 1 for event), or a logical vector (with TRUE for events and FALSE for non-events). The second argument is the vector of model probabilities obtaned with predict(). library(ResourceSelection) hoslem.test(d$outcome == &quot;Dead&quot;, predict(m_tf, type=&quot;response&quot;)) Hosmer and Lemeshow goodness of fit (GOF) test data: d$outcome == &quot;Dead&quot;, predict(m_tf, type = &quot;response&quot;) X-squared = 7.9975, df = 8, p-value = 0.4337 In this case, the p value from the test does not reject the null hypothesis that model m_tf is correct at the usual 0.05 \\(\\alpha\\)-level. 2.5.3 Other measures of fit Goodness of fit measures in the vein of \\(R^2\\) for GLMs are also available for LRMs. One such measure is the McFadden’s \\(pseudo-R^2\\), but these exceed the ambitions of this book (for the interested reader, a link to a blog post on this measure is provided in the resources section at the end of this chapter). 2.6 Model predictions and classification Logistic regression analyses are often is done for predictive purposes. This is the case of prognostic models, such as the burns example: it would be interesting to predict the outcome when a patient with burns is admitted to the hospital. In this cases, a more focused way to assess the utility of a LRM is by looking at how well the model classifies the observations. Let’s see how. 2.6.1 Predictions and confusion matrix First we need to compute the model predictions with predict(). However, by default, predict() wil provide log-odds (probabilities in the logit scale). If we want to get the probabilities themselves, we need to use the argument type = “response”: predicted_prob &lt;- predict(`m_tf`, type = &quot;response&quot;) predicted_prob %&gt;% head() 1 2 3 4 5 6 0.29686890 0.02377125 0.01889882 0.01889882 0.08549355 0.02767979 Then we need to use this probabilities to guess if a case has presented, or not present, the outcome. A reasonable decision is to assume the outcome is present if the probability is higher than 0.5. So, we can compute this guess with an ifelse() statement. Last, we crosstabulate the guess with the actual value of the outcome variable outcome: guess &lt;- ifelse(predicted_prob &gt; 0.5, &quot;Dead&quot;, &quot;Alive&quot;) table(guess, d$outcome) guess Alive Dead Alive 837 79 Dead 13 71 This cross tabulation of cases according to their actual value of the outcome variable and the model-based prediction is sometimes called a confusion matrix. Different measures can be derived from the confusion matrix, such as: Classification accuracy, which is the proportion of correct predictions: (837 + 71) / 1000 = 0.908 or 90.8%. Sensitivity, which the proportion of deaths that are correctly classified: 71 / (71 + 79) = 0.473 or 47.4%. Specificity, which the proportion of survivors that are correctly classified: 837 / (837 + 13) = 0.985 or 98.5%. Youden index = sensitivity + specificity - 1; 0.908 + 0.473 - 1 = 0.381. Sensitivity and specificity are the main measures of the accuracy of a diagnostic or prognostic marker. The higher they are, the better the marker will be able to discriminate the two states it is supposed to distinguish. However, a problem with them is that the confusion matrix from which they are computed depends on the cutpoint used to dichotomize the probabilities predicted by the model. Figure 2.2 shows the distributions of predicted probabilities by outcome, and the threshold used on these probabilities to guess the outcome (dashed line). The confusion matrix is nothing but counting how many cases there are on each side of the dashed line, for both outcomes (Alive or Death). gf_jitter(predicted_prob ~ outcome, data = d, alpha = 0.3, color = ~fct_rev(outcome), show.legend = FALSE) %&gt;% gf_hline(yintercept=0.5, linetype = 2) + coord_flip() Figure 2.2: Model 1 predicted probabilities by outcome Although the 0.5 threshold we chose to guess the outcome may look reasonable, it is anyway arbitrary. The problem is then, how would the sensitivity and specificity change if we chose a different threshold? The solution to this question in the next section. 2.6.2 ROC curves and AUC Receiver operating characteristic (ROC) curves are a common way to asses the accuracy of a diagnostic or prognostic method that produces a quantitative result. A ROC curve is a graphical representation of the sensitivity and specificity values we get by changing the threshold to guess a death. Package pROC allows to plot ROC curves. The roc() function in this package computes a roc object, that can be plotted with the base R function plot(). We have used the optional argument print.thres to mark the “best” threshold, that is, the one that maximizes the Youden index (the sum of sensitivity and specificity minus one): library(pROC) m_tf_roc &lt;- roc(d$outcome ~ predicted_prob) plot(m_tf_roc, print.thres = &quot;best&quot;) Figure 2.3: ROC curve for model m_tf Figure 2.3 shows the ROC curve for the probabilities computed from model m_tf. This was built by computing the sensitivity and the complementary of specificity (1-specificity) resulting from each possible threshold; each threshold contributes a point to the ROC curve, which results from joining the points. The point marked in the ROC curve is the one that maximizes the Youden index (and therefore the sum of senitivity and specificity), and corresponds to the threshold 0.158, which results in a specificity of 0.879 and a sensitivity is 0.773. We can easily verify this by computing the confusion matrix for this threshold: guess &lt;- ifelse(predicted_prob &gt;= 0.158, &quot;Dead&quot;, &quot;Alive&quot;) table(guess, d$outcome) guess Alive Dead Alive 747 34 Dead 103 116 From this confusion matrix, the specificity is 747 / (747+103) = 0.879, and the sensitivity is 116 / (116 + 34) = 0.773. In general, a ROC curve closely approaching the upper left corner (which corresponds to a sensitivity and specificity of 1) reflects a good discrimination ability. Conversely, a ROC curve very close to the diagonal indicates very poor discrimination ability. The area under the curve (AUC) is a measure frequently used to characterize the discrimination ability of a marker, since it will be high when a curves approaches the upper left corner, and low when it is close to the diagonal. AUC values can range from 0 to 1, and the higher its value the better the discrimination ability of a marker. The AUC of the ROC curve of figure 2.3 can be easily computed with function auc() on the roc object m_tf_roc: auc(m_tf_roc) Area under the curve: 0.8877 A 95% CI for the AUC can be obtained with function ci.auc(): ci.auc(m_tf_roc) 95% CI: 0.8552-0.9202 (DeLong) In this case, the “marker” is the probability computed from model m_tf, and an AUC value of 0.8877 is quite high. This indicates that model m_tf has a reasonably good prognostic ability. 2.7 Comparing models Competing models can be compared according to how good is the fit, or according to their discrimination ability. Let’s fit a second LRM including age as an additional predictor and get the summary: m_tfa &lt;- glm(outcome == &quot;Dead&quot; ~ tbsa + flame + age, family = binomial, data = d) summary(m_tfa) Call: glm(formula = outcome == &quot;Dead&quot; ~ tbsa + flame + age, family = binomial, data = d) Deviance Residuals: Min 1Q Median 3Q Max -2.86594 -0.27452 -0.10350 -0.03659 2.79049 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -7.891840 0.620523 -12.718 &lt;2e-16 *** tbsa 0.096450 0.008719 11.062 &lt;2e-16 *** flameYes 0.744372 0.336474 2.212 0.0269 * age 0.077424 0.007911 9.787 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 845.42 on 999 degrees of freedom Residual deviance: 357.79 on 996 degrees of freedom AIC: 365.79 Number of Fisher Scoring iterations: 7 The result of the Wald test for age suggests it is related to the outcome. But let’s see if the inclusion of age in the model results in a better fit, according to the LRT: anova(m_tf, m_tfa, test = &quot;LRT&quot;) Analysis of Deviance Table Model 1: outcome == &quot;Dead&quot; ~ tbsa + flame Model 2: outcome == &quot;Dead&quot; ~ tbsa + flame + age Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) 1 997 516.68 2 996 357.79 1 158.89 &lt; 2.2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We see that by adding a coefficient for age the deviance has dropped by 158.89, wich on a single degree of freedom is highly significant. Therefore, adding age to the model results in a significant improvement in the fit. To see if the improvement in the fit is worth the greater complexity of the model, we can compare the AIC of both models with function AIC(): AIC(m_tf, m_tfa) df AIC m_tf 3 522.6766 m_tfa 4 365.7903 Because the AIC is much lower for model m_tfa, this model is preferable. Now let’s look at the discrimination ability of both models, by plotting their ROC curves. We need to compute the roc object for this model, and then plot it along with the roc object computed previously for model m_tf. Note the argument add = TRUE in the second call to plot(), to overlay this curve to the previous one (instead of producing a different graphic): m_tfa_roc &lt;- roc(d$outcome ~ predict(`m_tfa`, type = &quot;response&quot;) ) plot(m_tf_roc, col = &quot;steelblue&quot;) plot(m_tfa_roc, col = &quot;darkred&quot;, add = TRUE) Figure 2.4: ROC curve for models m_tf (blue) and m_tfa (red) Looking at the figure, it is clear that model m_tfa has a better discrimination ability than model m_tf. Let`s compute the AUCs for these models: auc(m_tf_roc) Area under the curve: 0.8877 auc(m_tfa_roc) Area under the curve: 0.9581 We see that model m_tfa has a higher AUC than model m_tf. Now, we could test for the significance of the difference in AUCs with function roc.test(), passing it as arguments the two roc objects to be compared : roc.test(m_tf_roc, m_tfa_roc) DeLong&#39;s test for two correlated ROC curves data: m_tf_roc and m_tfa_roc Z = -4.8281, p-value = 1.379e-06 alternative hypothesis: true difference in AUC is not equal to 0 95 percent confidence interval: -0.09901206 -0.04183500 sample estimates: AUC of roc1 AUC of roc2 0.8877176 0.9581412 The output shows a very low p value, which provides evidence of a statistically significant difference in AUC. Therefore, we can conclude that model m_tfa has a better discrimination ability than model m_tf. The output also shows the 95% CI for the difference in AUC. Therefore, from this output we can conclude that the AUC of model m_tfa is 0.042 to 0.099 higher than that of model m_tf. The previous test (known as DeLong’s test) assumes a normal distribution of the marker in both outcome groups. If the assumption is not reasonable, a bootstrapped test can be produced with argument method = \"bootstrap\" (see ?roc.test). In this case this would be more appropriate since the distribution of the model predicted probabilities is quite assymetric (see figure 2.2), but the result is similar (result not shown) due to the robustness of DeLong’s test when the sample size is as high as it is in this case. In summary, model m_tfa is superior to model m_tf in terms of both fitting the data and discriminating the two possible outcomes (dead or alive). 2.8 Confounding LRM can be used to assess confounding, and to get ORs adjusted for confounders. Let’s fit a univariate LRM to asses the effect of inhalation injury on the outcome, and get the exponentials of the model coefficients: m_i &lt;- glm(outcome == &quot;Dead&quot; ~ inh_inj, family = binomial, data = d) exp(coef(m_i)) (Intercept) inh_injYes 0.09750 14.76923 From the output we see that the OR for inh_injYes is 14.77, implying that the odds of dead is more than fourteen times higher when there is inhalation injury than when there is not. However, inh_inj and tbsa are highly related, as can be seen in figure 2.5: gf_boxplot(tbsa ~ inh_inj, data = d) + coord_flip() Figure 2.5: Boxplot of tbsa by inh_inj This may suppose that, when we look at the association of inh_inj and the outcome without taking tbsa into account, the effect of tbsa and that of inh_inj are confounded. To see if this is the case, let’s fit a model with both tbsa and inh_inj, and estimate the OR from this model: m_ti &lt;- glm(outcome == &quot;Dead&quot; ~ tbsa + inh_inj, family = binomial, data = d) exp(coef(m_ti)) (Intercept) tbsa inh_injYes 0.03406189 1.07563276 3.63233807 Acording to this model, the OR for the inhalation injury is 3.63. This OR is adjusted for tbsa, and is much lower than 14.77. So, this is a case where tbsa acted as a confounder when we estimated the effect of inhalation injuries in the univariate LRM. The term adjusted OR, which is quite common in the medical research literature, means that the OR has been estimated from models that include potential confounders. 2.9 Interaction (effect modification) We could think that the effect of flames ca be different depending on the age of patients. To test this, we can fit a model with an additional term representing the interaction of flame and age. In function glm(), interaction terms are specified just a in function lm() for GLMs. Here we use the asterisk to specify an interaction between flame and age: m_tfa_int &lt;- glm(outcome == &quot;Dead&quot; ~ tbsa + flame * age, family = binomial, data = d) Let`s get a summary of this model: summary(m_tfa_int) Call: glm(formula = outcome == &quot;Dead&quot; ~ tbsa + flame * age, family = binomial, data = d) Deviance Residuals: Min 1Q Median 3Q Max -2.84247 -0.27258 -0.09219 -0.01056 2.85182 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -10.482093 1.273295 -8.232 &lt; 2e-16 *** tbsa 0.098108 0.008993 10.909 &lt; 2e-16 *** flameYes 3.816893 1.234002 3.093 0.00198 ** age 0.118519 0.018188 6.516 7.21e-11 *** flameYes:age -0.050326 0.018760 -2.683 0.00731 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 845.42 on 999 degrees of freedom Residual deviance: 349.76 on 995 degrees of freedom AIC: 359.76 Number of Fisher Scoring iterations: 8 The result of the Wald test for the interaction term flameYes:age provides some evidence of an interaction between flames and age (p = 0.007). Another (possibly better) way to judge the existence of an interaction is to compare the fits of this model and the model without the interaction term by a LRT: anova(m_tfa, m_tfa_int, test = &quot;LRT&quot;) Analysis of Deviance Table Model 1: outcome == &quot;Dead&quot; ~ tbsa + flame + age Model 2: outcome == &quot;Dead&quot; ~ tbsa + flame * age Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) 1 996 357.79 2 995 349.76 1 8.0272 0.004608 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 From this output, we see that the addition of the interaction term results in a drop of 8.0272 in the residual deviance, which on one degree of freedom (for one additional parameter) is statistically significant according to the LRT (p = 0.004). Last, we can look at the AIC of both models: summary(m_tfa)$aic [1] 365.7903 summary(m_tfa_int)$aic [1] 359.7631 The lower AIC of the model with interaction indicates a better fit of this model. So, according to all three criteria (Wald test, LRT and AIC), the model containing an interaction between age and flames provides a better representation of the data. Because an interaction between two predictors means that the effect of one of them depends on the value of the other, this effect cannot be expressed as a single OR. For instance, from model m_tfa_int we cannot give a single OR to characterize the effect of flames model because this effect depends on age. In general, when a LRM contains an interaction term of a risk factor (say, \\(X_1\\)) and an effect modifier (\\(X_2\\)), we may want to compute the OR comparing two values of the risk factor (say, \\(X_1 = k_1\\), vs \\(X_1 = k_2\\)) for different values of the effect modifier \\(X_2\\). This can be done looking at the log_odds in such cases: When \\(x_1 = k_1: \\qquad log(\\frac{\\pi|X_1=k1}{1-\\pi|X_1=k1}) = \\beta_0 + \\beta_1 \\: k_1 + \\beta_2 \\: X_2+\\beta_{12} \\: k_1 \\: X_2\\) When \\(X_1 = k_2: \\qquad log(\\frac{\\pi|X_1=k2}{1-\\pi|X_1=k2}) = \\beta_0 + \\beta_1 \\: k_2 + \\beta_2 \\: X_2+\\beta_{12} \\: k_2 \\: X_2\\) The difference between these two log_odds will be the log of the OR: \\(log(\\frac{\\pi|X_1=k1}{1-\\pi|X_1=k1})-log(\\frac{\\pi|X_1=k2}{1-\\pi|X_1=k2}) \\quad = \\quad log(OR) \\quad = \\quad \\beta_1 (k_1-k_2) + \\beta_{12}(k_1-k_2) \\: X_2\\) An therefore the OR comparing the odds (\\(k_1\\) over \\(k_2)\\) is: \\[OR = e^{\\beta_1 \\: (k_1-k_2) + \\beta_{12} \\: (k_1-k_2) \\: X_2}\\] This equation shows how the value of the OR comparing two values of the risk factor (\\(k_1\\) vs \\(k_2\\)) depends on the value of the effect modifier \\(X_2\\). The computation and interpretation of ORs estimated in models with interaction terms is not as straightforward as in the case of models with main effects only (i.e, without interaction terms). For a worked example, see this video. 2.10 Model diagnostics Unlike the GLM, the LRM does not assume normality of the residuals. In terms of distributional assumptions, the LRM only assumes that the outcome variable follows a binomial distribution with mean and variance that depend on the explanatory variables. For this reason, the analysis of residuals is not as easy and informative as in the case of GLMs. The LRM implicitly assumes that the relation of continuous predictors is linear in the logit scale. To assess whether or not this assumption is reasonable, the fitted values can be plotted against each continuous predictor. Let’s do it for the m_tfa_int model: library(ggformula) p1 &lt;- gf_point(predict(m_tfa_int) ~ tbsa, data = d) + geom_smooth(method = &quot;loess&quot;) p2 &lt;- gf_point(predict(m_tfa_int) ~ age, data = d) + geom_smooth(method = &quot;loess&quot;) p1 + p2 In this case, the linearity of the logit for both tbsa and age is not perfect, but it is not completely unreasonable. Maybe the model could be improved by using a second degree polynomial for each of these variables, but this would increase the model complexity, and might not necessarily improve the predictive capacity of the model; exploring it is left to the student as an optional exercise. The detection of influential outliers can be easily made by looking at the plot of Cook’s distances that can be obtained as for GLMs: plot(m_tfa_int, 4) In this case, all Cook’s distances are below 0.5, so there is no reason to worry about influential observations. Resources Applied Logistic Regression, by D. Hosmer &amp; S. Lemeshow, is a very good book on LRM. A very synthetic post in R-bloggers on evaluating LRMs. McFadden’s \\(pseudo-R^2\\) is a There are several \\(R^2\\)-like measures for LRMs, such as McFadden’s \\(pseudo-R^2\\). A shiny app to illustrate ROC curves can be found here: play with the threshold slider (and with the separation) to see what happens. An R-bloggers post on how to fit a LRM with aggregated (grouped) data. When there are many potential predictor variables, the number of possible models can be very large, and it is not feasible to fit and assess them one at a time. Read about model selection methods here and here. A classical, yet interesting article on the important concept of validation of prognostic models; and a another, more recent article on the validation of prediction models. Exercises In section 2.1 we stated that equations (2.1) and (2.2) are equivalent. Can you prove it? Suppose a logistic regression model includes a categorical variable smoker as predictor, and it is a factor with levels never, past and current. How many model coefficients refer to variable smoke? What do they correspond to? What is the interpretation of the exponentials of these coefficient(s)? For each categorical variable (gender, race, flame and inh_inj), fit a univariate LRM, and: compute the exponential of the model coefficient of the predictor variable. compute the contingency table of the predictor variable and outcome; from this table, compute the OR and compare it to the OR estimated from the LRM. Fit a LRM for outcome == \"Dead\" including all remaining variables in the dataset as predictors (call this model m1) and answer the following questions: According to the Wald test results, is there evidence of association with outcome for all predictors? What is the residual deviance of this model? What are the degrees of freedom and why? What is the AIC? Fit a simpler model by removing the predictors with no evidence of association to the outcome according to the Wald tests results (call this model m2): What are now the residual deviance, the degrees of freedom and the AIC? Compare models m1 and m2 with a LRT and interpret the result. Which of m1 and m2 is preferable according to the AIC? Compute and interpret the ORs (and 95% CI) estimated from this model (give the OR for a 10 units increase of quantitative variables). The prognosis of many clinical conditions gets worse with age. It is therefore reasonable to think that age could be an effect modifier of tbsa or inh_inj. Check for a possible interaction of age with these two variables by adding appropriate interaction terms to model m2 (and call this new model m3). What are now the residual deviance, the degrees of freedom and the AIC? Compare models with a LRT and interpret the result. Which of m2 and m3 is preferable according to the AIC? Plot the ROC curve of models m1 m2 and m3, and: compute the AUCs and corresponding 95% CIs using the bootstrap method (hint: look at the method argument in the help of function ci.auc()). compare the AUCs with a) the DeLong’s test, and b) the bootstrap test. Are the p values of the two tests very different? Do they lead to different conclusions? Which of the three models you think is preferable to be used as a prognostic tool? For the model you think is preferable, determine the best threshold to maximize the Youden index, and produce the confusion matrix. How many different models (containing at least the intercept term and no interaction terms) could be fitted with the explanatory variables in the burns dataset? If only the variable name is used in the left hand side of the formula, e.g., glm(outcome ~ ...),then the second level of the factor outcome would be modeled. In this case, “Dead” is the second level of outcome, so that we could have attained the same result with glm(outcome ~ tbsa + flame, family = binomial, data = d). However, it is safer to explicitly state the level whose probability we want to model.↩︎ "],["survival-analysis-and-cox-regression-models.html", "3 Survival analysis and Cox regression models 3.1 Time to event variables (T) 3.2 Censoring 3.3 Survival objects in R 3.4 Survival and related functions 3.5 Estimating the survival function 3.6 Estimating the survival function in independent samples 3.7 Comparing the survival function in independent samples 3.8 The Cox model 3.9 Fitting a Cox model 3.10 Assessing the proportional hazards (PH) assumption Resources Exercises", " 3 Survival analysis and Cox regression models In this unit, we introduce several analysis methods that are collectively referred to as survival analysis. As the name suggests, these methods are used to analyse survival times, but not only. In fact, they can be used to analyse the time to an event of interest, regardless of what this event is (death or other). Common goals of survival analysis are: To estimate the survival function, which describes the probability of survival as a function of time. To compare survival functions among several populations of individuals (e.g., males vs females, treated vs non-treated, etc.) To model survival as a function of potential explanatory variables (like age, gender, prognostic markers, treatment received). In the following sections we present methods to accomplish all these objectives, but first we must introduce some theoretical concepts on which these methods are based. Let’s start by clarifying what is the type of variables we can analyse with these methods. 3.1 Time to event variables (T) By survival time we mean the time from an initial point (such as the diagnosis of a malignancy) to death. Therefore, survival times are time intevals defined by a starting point and the event “death”. While survival times are measured in many studies on life threatening diseases such as cancer, other time intervals may be of interest in both cancer and many other research areas. Here are some examples: the time from surgery to disease progression in cancer patients. the time from transplant to graft rejection in transplant patients. the time from atrioventricular node ablation to arrhythmia recurrence in patients with atrial fibrillation. the time to pain relief after taking an analgesic drug. All of these examples assess the time to an event (whether disease progression, graft rejection, arrhythmia recurrence, or pain relief). We refer to these as time-to-event variables, and usually denote them by T. Note, however, that an unambiguous definition of a time interval requires not only specifying the event of interest, but also the starting point from which we begin counting time. While time to event variables are continuous in nature, their analysis presents some challenges that do not affect other types of continuous variables (like the weigh of a newborn, or the blood concentration of cholesterol). Tipically, time to event variables tend to show a markedly asymmetric distribution, and some cases may show very long times. Because of this, it is impractical, if not impossible, to observe the complete time interval for some cases, since we would have to wait a long time for the event to appear in all of them. This generates a problem known as censoring, which we discuss in the next section. 3.2 Censoring Consider a hypothetical survival study that recruits patients starting from 01 January 2015. Recruitment is completed two years later (01 January 2017) and then, patients are followed for five additional years untill study finalisation on 01 january 2023. Figure 3.1 illustrates the enrollment and follow-up (horizontal lines) of patients up to death (dots) or study termination. Dashed lines indicate study start, end of recruitment and end of study. Figure 3.1: Chronolgy of enrollment and follow-up of patients Most of the 15 patients died at some point, so that we know what is the survival time for them . However, there are four patients that did not die during the follow-up: patients 9, 11 and 13 were alive by the end of study, and patient 8 was lost to follow up after about 4 years (1460 days). These are called censored observations beacuse we only observed part of their survial time, but not all of it. While we cannot know what is the actual survial time for these patients, we know it is greater than the time we followed them. For instance, we know that the survival time for patient 8 is greater than 4 years. Censored observations are commonplace in time to event studies. While it may not be obvious how to deal with them in the analysis, it is important to understand that we cannot simply ignore censoring. On the one hand, taking the observed follow-up time as the survival time would underestimate it. On the other hand, removing censored observations from the analysis on the grounds that we ignore the actual survival time would produce an even greater underestimation, since these cases are the ones with the longest survival. Censoring can happen in different forms when measuring time to an event, and it is usual to distinguish: Right censoring: this is the case when we know the starting point, but the follow-up is interrupted (for whatever the reason) before the event is observed. This is the case affecting the hypotthetical study of figure 3.1 and most survival studies, or more generally, most time to event studies. Left censoring: this is the case when we do not know the starting point, but a follow-up has been initiated after it, and has continued until the event is observed. This would be the case if we wanted to estimate the time of evolution of a disease until some complication (or death); since many chronic diseases are not diagnosed when they appear but some time thereafter, starting follow-up at the diagnostic date implies left-censoring of the true time of evolution of the disease. Interval censoring: this is the case when we know the starting point, but patients are monitored at discrete times rather than continuously (for instance, once a year), so that when the event is observed, we cannot know the exact date it appeared. For instance, if a patient does not show the event in the first three yearly controls but shows it at the fourth year control, we only know that the time to the event is some value between 3 and 4 years, but we ignore the precise value. The methods presented in this unit are appropriate to deal with right censoring only, but fortunately this is the most common type of censoring in clinical studies. Moreover, these methods assume that the censoring is non-informative, which means it is not related to the probability of occurrence of the event. Conversely, informative censoring refers to the case where the censoring is related to the probability of ocurrence of the event, and this may cause biased survival estimates. 3.3 Survival objects in R Figure 3.2 shows the follow-up and events for the same patients of figure 3.1, but now sorted by follow-up length, as well as the dataframe containing the relevant data. Note that two variables are needed: one for the duration of follow-up (days), and another one for the patient’s status at the end of follow-up (event), so that events can be distinguished from censored observations. In this case, the event has been coded as 1, while 0 indicates a censored observation. Figure 3.2: Length of follow-up and data The survival package has a function Surv() (note the capital S in Surv !) allowing to combine the duration of follow-up (passed as first argument) and the event indicator (second argument) into a single survival object. Assuming the dataframe shown in 3.2 has name d, the following will produce a survival object: library(survival) Surv(d$days, d$event) [1] 274 549 611 1066 1185 1188 1400 1472+ 1736 1887 1918 2253 [13] 2265+ 2419+ 2462+ The result looks much like a numeric vector of follow-up lengths, but it is not: censored observations have been suffixed with a plus sign (which is not possible in standard numeric vectors). As we will see below, survival objects are what we need to analyze survival times. Note that the Surv() function expects the event indicator to be coded in any of the following ways: TRUE/FALSE, where TRUE is event and FALSE is censored, or 1/0, where 1 is event and 0 is censored; or 2/1 where 2 is event and 1 is censored. When creating a survival object it is very important to ensure that the event indicator is coded in one of these ways. In dataframe d, the event indicator d$event is coded as the second case above (1/0, where 1 is event and 0 is censored), and therefore the survival object created in the previous script is correct. Equivalently, we could have defined the survival object as: Surv(d$days, d$event == 1) [1] 274 549 611 1066 1185 1188 1400 1472+ 1736 1887 1918 2253 [13] 2265+ 2419+ 2462+ Note that in this case we are using the first coding above, since the comparison d$event == 1 will produce a logical vector, with TRUE for cases with event (1), and FALSE for non-events (0). This syntax has the advantages of making explicit the value of the event variable that corresponds to event cases. 3.4 Survival and related functions For a survival (or time to event) variable \\(T\\) taking values \\(t_1, t_2, ..., t_n\\) in a sample of \\(n\\) individuals, the survival function is defined as the probability that an individual survives (or remains event-free beyond) time \\(t\\). Formally, \\[S(t) = P(T&gt;t)\\] It is assumed that \\(S(0) = 1\\) and \\(S(\\infty) = 0\\). The first of these assumptions means that all individuals are initially (\\(t=0\\)) alive (or event-free), and the second one means that no individual survives forever: all individuals will eventualy die (or experience the event) (\\(t=\\infty\\)). Because once an individual dies (or experiences the event) he or she will never resurrect (or be event-free), \\(S(t)\\) is a non-increasing function: it can only decrease with time or remain stable, but never increase. There are some important functions that are closely related to the survival function. First, the cumulative distribution function, is just the complementary of the survival function: \\[F(t) = 1 - S(t)\\] This functions gives the probability of presenting the event at time \\(t\\) or before, and this is why it is sometimes calles the cumulative events function. Another function related to the survival function is the hazards function, which can be defined as the differential of the log of \\(S(t)\\) with respect to \\(t\\), with the sign changed: \\[h(t) = - \\frac{d \\;log \\;S(t)}{dt}\\] Since this function involves a differential of (the log of) \\(S(t)\\), it describes the rate at which (the log of) \\(S(t)\\) changes, and is interpreted as the instantaneous death or event rate. The hazard function is not a probability, but an instantaneous rate. Last, the cumulative hazard function, is the log of the survival function with changed sign: \\[H(t) = - log \\ S(t)\\] This function gives accumulated risk until time \\(t\\), but it is not a probability, and has no easy interpretation. 3.5 Estimating the survival function We previously discussed the importance of taking censoring into account to estimate survival probabilities. Here we present a method to estimate the survival function in the presence of censoring, known as the Kaplan-Meier (KM) method. The KM estimate of the survival function at time \\(t_i\\) is: \\[S(t_i) = S(t_{i-1}) \\left( 1-\\frac{d_i}{n_i} \\right)\\] where \\(d_i\\) is the number of events observed at time \\(t_i\\), and \\(n_i\\) is the number of individuals at risk inmediately before time \\(t_i\\). This estimate is computed for all event times \\(t\\) observed in a sample, thus obtaining an empirical estimate of the survival function. To get the KM estimates from a sample of survival times, we first use function survfit() from the survival package: the first argument to this function is a formula, with a survival object produced with Surv() before the tilde, and 1 after the tilde; the dataframe containing the variables is passed as second argument. We save the resulting object (as fit) for later use, and then summarise it: fit &lt;- survfit(Surv(days, event) ~ 1, d) summary(fit) Call: survfit(formula = Surv(days, event) ~ 1, data = d) time n.risk n.event survival std.err lower 95% CI upper 95% CI 274 15 1 0.933 0.0644 0.815 1.000 549 14 1 0.867 0.0878 0.711 1.000 611 13 1 0.800 0.1033 0.621 1.000 1066 12 1 0.733 0.1142 0.540 0.995 1185 11 1 0.667 0.1217 0.466 0.953 1188 10 1 0.600 0.1265 0.397 0.907 1400 9 1 0.533 0.1288 0.332 0.856 1736 7 1 0.457 0.1310 0.261 0.802 1887 6 1 0.381 0.1295 0.196 0.742 1918 5 1 0.305 0.1240 0.137 0.676 2253 4 1 0.229 0.1140 0.086 0.608 The output shows the times at which events were observed, and for each time, the number of cases at risk (n.risk), the number of events observed at this time (n.events), the KM estimate of the survival probability, its standard error and the lower and upper bounds of its 95% CI. We can easily verify that the survival estimates provided were computed using the KM estimator presented above: For \\(t=0: \\qquad \\qquad S(0) = 1\\) For \\(t=274 \\qquad \\qquad S(274) = 1 \\times \\left(1-\\frac{1}{15} \\right) = 1 \\times 0.933 = 0.933\\) For \\(t=549 \\qquad \\qquad S(549) = 0.933 \\times \\left(1-\\frac{1}{14} \\right) = 0.933 \\times 0.929 = 0.867\\) … and so on. Note that a survival probability is estimated for each time at which an event was observed, but not for times corresponding to censored cases. Note also that censored observations are removed from the set at risk. In the first 7 rows of the results above (times 274 to 1400), the number at risk decreases one at a time because all these patients presented the event and no observations were censored at before time 1400. However, patient 8 was censored after 1472 days of follow-up, so that it is no longer at risk to estimate survival at the next observed event, which occurred at 1736 days. For this reason, the number of patients at risk in row 1736 is not 8 but 7. The summary function can be used as well to obtain the survival estimates at specific times, by passing these times (as a numeric vector) in the optional times argument when calling summary(). Here we get the survival for the first five years: summary(fit, times = 365 * 1:5) Call: survfit(formula = Surv(days, event) ~ 1, data = d) time n.risk n.event survival std.err lower 95% CI upper 95% CI 365 14 1 0.933 0.0644 0.815 1.000 730 12 2 0.800 0.1033 0.621 1.000 1095 11 1 0.733 0.1142 0.540 0.995 1460 8 3 0.533 0.1288 0.332 0.856 1825 6 1 0.457 0.1310 0.261 0.802 3.5.1 Quantiles of the survival time Once we have fitted a survival function with survfit() and saved the resulting object, we can use it for several purposes. For instance, printing this object will provide us with the estimated median survival time, that is, the time at which 50% of the sample has shown the event: fit Call: survfit(formula = Surv(days, event) ~ 1, data = d) n events median 0.95LCL 0.95UCL [1,] 15 11 1736 1185 NA We see that the median survial time is 1736 days (about one year and three quarters), and the lower limit of the 95% CI is 1185 (the upper limit cannot be estimated in this case, due to the limited dample size). We could also estimate the quartiles from the fit object: quantile(fit) $quantile 25 50 75 1066 1736 2253 $lower 25 50 75 549 1185 1887 $upper 25 50 75 1887 NA NA The output shows the estimates of the three quartlies as well as the lower and upper bounds of their 95% CI. For instance, the 1st quartile (or 25th percentile) is 1066 days, with 95% CI ranging from 549 to 1887 days. The upper bound of the 95% CI for the median and 3rd quartile could not be estimated due to the limited sample size and the censoring of some observations. Other quantiles could be obtained by specifying their probabilities in argument probs. Here we estimate the 10th and 70th percentiles of the survival times: quantile(fit, probs = c(.1, .7)) $quantile 10 70 549 2253 $lower 10 70 274 1736 $upper 10 70 1400 NA 3.5.2 Plotting the estimated survival function The KM survival function can be plotted using the ggsurvplot() function of package survminer. The only required argument to this function is the fitted object, but there are lots of optional arguments we can use to customize the plot (see ?ggsurvplot). library(survminer) ggsurvplot(fit, xlab = &quot;Days&quot;, legend = &quot;none&quot;) In resulting plot, the estimated survival curve looks like a step function because the KM method provides survival estimates at discrete time points (follow-up times at which an event was observed). Censored observations are depicted along the survival line as + (unless we use option censor=FALSE in the function call). The colored band shows the 95% CI for each KM survival estimate, and therefore it is not a 95% CI for the whole survival function. As an alternative of plotting the survival function, we may want to plot the cumulative events function, whish is jus the complementary of the survival function, i.e., \\(1-S(t)\\). This can be done with option fun = \"event\" in ggsurvplot(): ggsurvplot(fit, xlab = &quot;Days&quot;, legend = &quot;none&quot;, fun = &quot;event&quot;) 3.6 Estimating the survival function in independent samples A very common reasearch objective is to estimate the survival function in different groups of individuals. To illustrate how this can be done, we will use the lung dataset included in the survival package, containing data on the survival of 228 patients with advanced lung cancer from the North Central Cancer Treatment Group: head(lung) inst time status age sex ph.ecog ph.karno pat.karno meal.cal wt.loss 1 3 306 2 74 1 1 90 100 1175 NA 2 3 455 2 68 1 0 90 90 1225 15 3 3 1010 1 56 1 0 90 90 NA 15 4 5 210 2 57 1 1 90 60 1150 11 5 1 883 2 60 1 0 100 90 NA 0 6 12 1022 1 74 1 1 50 80 513 0 In this dataset, time is the follow-up time in days, status is an indicator of censoring (1=censored, and 2=dead), and sex is coded as 1=male and 2=female (see ?lung for more details). Let’s define factor for sex: lung$sex &lt;- factor(lung$sex, levels = 1:2, labels = c(&quot;male&quot;, &quot;female&quot;)) Suppose we want to compare the survival function in males and females. Then, we need to estimate this function separately for each males and females. This can be done with survfit() but we need to specify the grouping variable sex in the formula, after the tilde. Here we save the result as km and then get the estimated survival times at one and two years: km &lt;- survfit(Surv(time = time, event = status) ~ sex, data = lung) summary(km, times = c(365, 730)) Call: survfit(formula = Surv(time = time, event = status) ~ sex, data = lung) sex=male time n.risk n.event survival std.err lower 95% CI upper 95% CI 365 35 85 0.3361 0.0434 0.261 0.433 730 7 24 0.0781 0.0276 0.039 0.156 sex=female time n.risk n.event survival std.err lower 95% CI upper 95% CI 365 30 36 0.526 0.0597 0.4215 0.658 730 6 14 0.187 0.0621 0.0978 0.359 Now the output of summary() gives survival estimates for males and females separately. At both one and two years of follow-up, the survival estimates are higher for females than for males. 3.7 Comparing the survival function in independent samples The survival functions estimated in different groups of individuals can be compared with the logrank test. In this test, the following hypotheses are stated: \\[H_0: \\qquad S_1(t) = S_2(t)\\] \\[H_1: \\qquad S_1(t) \\ne S_2(t)\\] where \\(S_1(t)\\) and \\(S_2(t)\\) are the survival functions in populations 1 and 2, respectively (e.g., males and females). The logrank test can be produced with function survdiff(). The first argument to this function is a formula, with a survival object produced with Surv() before the tilde, and the grouping variable after the tilde; the dataframe containing the variables is passed as second argument. The following code produces a logrank test comparing the survival of males and females in the lung dataset: survdiff(Surv(time = time, event = status) ~ sex, data = lung) Call: survdiff(formula = Surv(time = time, event = status) ~ sex, data = lung) N Observed Expected (O-E)^2/E (O-E)^2/V sex=male 138 112 91.6 4.55 10.3 sex=female 90 53 73.4 5.68 10.3 Chisq= 10.3 on 1 degrees of freedom, p= 0.001 The output shows, for each group, the number of cases (N), the number of events Observed, the number of events Expected under the null hypothesis, and two addition columns showing the computation of a chi-square statistic (which, in these case, it is called logrank statistic) that compares observed and expected frequencies. Finally, the logrank statistic (Chisq= 10.3) and the corresponding p value are given. A low p value provides evidence that the two populations compared do have a different survival function. Thus, in this case, because p= 0.001 is lower than the usual 0.05 significance level, we reject the null hypothesis of equal survival functions in males an females, and conclude their survival functions are different. Conveniently, function ggsurvplot() allows to depict the estimated sirvival functions, as well as the result of the logrank test, using appropriate options (pval = TRUE, and pval.method = TRUE), as shown below: ggsurvplot(km, pval = TRUE, pval.method = TRUE) The logrank test is appropriate to compare survival curves under the following conditions: the curves are estimated in independent groups. the censoring pattern is similar in all groups compared. at any time, the instantaneous risk of the event in the populations compared are proportional; this is the so-called proportional risk assumption. n practice, we may loosely consider this assumption is reasonable if the estimated survival functions do not cross. 3.8 The Cox model Cox models are very common when it comes to model survival data. However, it is not the survival function which is directly modeled, but the closely related hazard function. In a Cox model, the hazard function is expressed as the product of a baseline hazard and the exponential of a linear predictor of explanatory variables (\\(X_1, X_2, ..., X_p\\)) with no intercept: \\[\\begin{equation} h(t) \\quad = \\quad h_0(t) \\quad e\\ ^{\\ \\beta_1 X_1 + \\ \\beta_2 X_2 + ...+ \\ \\beta_k X_p} \\quad = \\quad h_0(t) \\quad e\\ ^{\\beta_1 X_1} \\ e\\ ^{\\beta_2 X_2} \\ ... \\ e\\ ^{\\beta_k X_p} \\tag{3.1} \\end{equation}\\] Note that the model above establishes the hazard at any time \\(t\\) as the product of two quantities: the baseline hazard \\(h_0(t)\\) and the exponential of a linear predictor of \\(p\\) explanatory variables \\(e^{\\ \\beta_1 X_1 + \\ \\beta_2 X_2 + ...+ \\ \\beta_k X_p}\\). The former depends on \\(t\\) but does not depend on the explanatory variables, while the later depends on the explanatory variables but does not depend on \\(t\\). The baseline hazard \\(h_0(t)\\) is the value of the hazard function \\(h(t)\\) when all explanatory variables are equal to 0, since \\(e^{\\ \\beta_1 \\times 0 + \\ \\beta_2 \\times 0 + ...+ \\ \\beta_k \\times 0} = e ^ 0 = 1\\) The exponentials of the model coefficients \\(\\beta_1, \\beta_2, ..., \\beta_p\\) are interpreted as hazard ratios. To se this, suppose \\(X_1\\) is a dichotomous variable coded as 0 or 1, and let’s compare the hazards \\(h(t)\\) that will result when \\(X_1 = 0\\), or when \\(X_1 = 1\\), assuming all other explanatory variables remain unchanged: \\(X_1 = 0: \\qquad \\qquad h(t|X_1 = 0) = h_0(t) \\quad e\\ ^{\\beta_1 \\times 0} \\ e\\ ^{\\beta_2 X_2} \\ ... \\ e\\ ^{\\beta_k X_p} = h_0(t) \\quad e\\ ^{0} \\ e\\ ^{\\beta_2 X_2} \\ ... \\ e\\ ^{\\beta_k X_p}\\) \\(X_1 = 1: \\qquad \\qquad h(t|X_1 = 1) = h_0(t) \\quad e\\ ^{\\beta_1 \\times 1} \\ e\\ ^{\\beta_2 X_2} \\ ... \\ e\\ ^{\\beta_k X_p} = h_0(t) \\quad e\\ ^{\\beta_1} \\ e\\ ^{\\beta_2 X_2} \\ ... \\ e\\ ^{\\beta_k X_p}\\) Since \\(e\\ ^0 = 1\\), dividing these two equations we get: \\[\\frac{h(t|X_1 = 1)}{h(t|X_1 = 0)} = \\frac{h_0(t) \\quad e\\ ^{\\beta_1} \\ e\\ ^{\\beta_2 X_2} \\ ... \\ e\\ ^{\\beta_k X_p}}{h_0(t) \\quad e\\ ^0 \\ e\\ ^{\\beta_2 X_2} \\ ... \\ e\\ ^{\\beta_k X_p}} = \\frac{e\\ ^{\\beta_1}}{e\\ ^0} = e\\ ^{\\beta_1}\\] This result implies that the hazard ratio on the left hand side of the previous equation is constant and not depend on \\(t\\). For this reason, the Cox model is sometimes called the Cox proportional hazards model. 3.9 Fitting a Cox model A Cox model can be fitted with function coxph() from package survival. The first argument is a formula with a survival object before the tilde, and one or more explanatory variables after the tilde; the dataframe containing the variables appearing in the formula is passed as a second argument. Here we fit a Cox model for the lung data using sex as the only explanatory variable, and then summarize the resulting object cm1: cm1 &lt;- coxph(Surv(time, status) ~ sex, data = lung) summary(cm1) Call: coxph(formula = Surv(time, status) ~ sex, data = lung) n= 228, number of events= 165 coef exp(coef) se(coef) z Pr(&gt;|z|) sexfemale -0.5310 0.5880 0.1672 -3.176 0.00149 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 exp(coef) exp(-coef) lower .95 upper .95 sexfemale 0.588 1.701 0.4237 0.816 Concordance= 0.579 (se = 0.021 ) Likelihood ratio test= 10.63 on 1 df, p=0.001 Wald test = 10.09 on 1 df, p=0.001 Score (logrank) test = 10.33 on 1 df, p=0.001 The output starts by informing on the sample size n = 228 and the number of events = 165. Then, a first table shows the estimated beta coefficient (coef) for sexfemale, as well as its exponential (exp(coef)), standard error (se(coef)) and the result of a Wald test assessing the null hypothesis that the population coeffiicient is 0 (which implies no effect of the explanatory variable on the hazard function). In this case, the small p value (0.001) provides evidence that the hazard function is different for males and females. The exponential of the model coefficient is the hazard ratio comparing females to males, that is \\(\\frac{h(t|female)}{h(t|male)} = 0.5880\\), which implies that the hazard is lower in females than in males. In a second table, we see the lower and upper bounds of the confidence interval for the exponential of the model coefficient, so that we can conclude that the hazard ratio comparing females to males is 0.588 with 95% CI ranging from 0.4237 to 0.816. The column exp(-coef) = 1.701 is nothing but the inverse of 0.588, and therefore is the hazard ratio comparing males to females, that is \\(\\frac{h(t|male)}{h(t|female)} = \\frac{1}{0.588} = 1.701\\). Finaly, the output provides three different tests of the overall model fit, in which a small p value means the model fits the data better than the null model (i.e., a model with the baseline hazard only). All three tests provide very similar results, with an identical p value rounded to the third decimal (_p_ = 0.001). Let’s now fit a second Cox model with additional predictors age and ph.ecog, the ecog performance status scale: cm2 &lt;- coxph(Surv(time, status) ~ sex + age + ph.ecog, data = lung) summary(cm2) Call: coxph(formula = Surv(time, status) ~ sex + age + ph.ecog, data = lung) n= 227, number of events= 164 (1 observation deleted due to missingness) coef exp(coef) se(coef) z Pr(&gt;|z|) sexfemale -0.552612 0.575445 0.167739 -3.294 0.000986 *** age 0.011067 1.011128 0.009267 1.194 0.232416 ph.ecog 0.463728 1.589991 0.113577 4.083 4.45e-05 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 exp(coef) exp(-coef) lower .95 upper .95 sexfemale 0.5754 1.7378 0.4142 0.7994 age 1.0111 0.9890 0.9929 1.0297 ph.ecog 1.5900 0.6289 1.2727 1.9864 Concordance= 0.637 (se = 0.025 ) Likelihood ratio test= 30.5 on 3 df, p=1e-06 Wald test = 29.93 on 3 df, p=1e-06 Score (logrank) test = 30.5 on 3 df, p=1e-06 The output strart by informing that 1 observation deleted due to missingness. In the table below, the Wald tests indicate that both sex and ph.ecog may be important prognostic variables. While there is no no evidence that the hazard of death (and therefore survival) is affected by age, it is quite obvious that the hazard of death increases with age (as suggested by the value 1.0111, corresponding to a one year increase in age), so that we may decide to keep this variable in the model despite the non-significant Wald test. The hazard ratio of sexfemale is very similar to that estimated in the cm1 model; and the hazard ratio corresponding to a unit increase in the ecog performance status scale is 1.59, which implies a 59% increase in the hazard per unit increase in the ecog performance status scale. The last part of the output shows the results of several tests (likelihood ratio, Wald and log-rank) assessig the overall model. A significant result in these tests provides evidence that the model explains some variability in survival. In addition, the so called concordance statistic is shown. Concordance is defined as the probability of agreement for any two randomly chosen observations, where in this case agreement means that the observation with the shorter survival time also has the larger risk score. The theoretical range for this statistic is 0 to 1, and the closer to 1, the better the fit. The results of a Cox model fit can be displayed graphically on a forest plot. This can be produced with function ggforest() of package survminer. The fit object is the only argument we need to pass to this function, but here we use the optional argument fontsize to make the resulting graphic more readable: ggforest(cm2, fontsize = 1) Figure 3.3: Forest plot for the estimated effects of model cm2 Figure 3.3 shows the estimated hazard ratios (HR) for all explanatory variables of model cm2. For factors (sex), the HR for the (first) reference level is always 1, since it compares the reference level with itself (which not very useful); then, the HR for all remaining levels compared to the reference level are displayed. For quantitative variables, the hazard ratios correspond to a unit increase in the variable value. In all cases, the point estimate of the hazard ratio is depicted as a square, and 95% CIs are shown. In the case of age the CI is so narrow that it is hidden by the square. 3.10 Assessing the proportional hazards (PH) assumption As we have seen in previous sections, the Cox model assumes that the hazard ratios are are proportional and do not depend on \\(t\\). This is an important assumption, often a simplification of reality, and we should assess to what extent the simplification is reasonable. The PH assumption can be checked with function cox.zph() from the survivalpackage. The fit object is passed as argument to this function. Here we test model cm2 fitted above for the PH assumption: cm2_ph &lt;- cox.zph(cm2) cm2_ph chisq df p sex 2.305 1 0.13 age 0.188 1 0.66 ph.ecog 2.054 1 0.15 GLOBAL 4.464 3 0.22 The output shows the result of significant tests for the PH assumption. There is one such test for each predictor variable in the model, plus an overall test (GLOBAL). A low p value in these tests provides evidence of violation of the PH assumption (i.e., evidence of non-proportional hazards). In this case, there is no evidence of non-PH, so that the PH assumption seems reasonable. When the PH assumption is violated, there are to possible ways to account for it. First, if the PH assumption is violated for a single explanatory variable, and we are not particularly interested in modeling the efect of this variable, a stratified Cox model can be fitted using this variable to define the strata (see the examples section of ?coxph). As a second option, other types of models can be used, such as the so called accelerated failure time models. While these are out of the scope of this course, we provide some links to materials covering both options in the resource section. Resources Some books on survival analysis: David G. Kleinbaum &amp; Mitchel Klein. Survival Analysis: A Self-Learning Text (Third Edition) Dirk F. Moore. Applied Survival Analysis Using R Fore more on assessing the PH assumption, as well as influential observations, see here. Some articles to learn how to deal with non-proportional hazards: Dealing with non-proportional hazards in R. Extensions of Cox model for non-proportional hazards purpose. Survival vignette in the survival package). Accelerated failure time models. Have a look at this Survival analysis/plots cheat sheet A couple of very good books in modeling, in general: F. Harrell. Regression modeling strategies T. Hastie, R. Tibshirani &amp; J. Friedman Exercises In section 3.8 we proved that, when a predictor is categorical, the exponential of its coefficient is a hazard ratio. Prove that, when there is a quantitative predictor in a Cox model, the exponential of its coefficient is a hazard ratio corresponding to a unit increase in the predictor. Using the ovarian dataset in package survival (see ?ovarian), define factors for rx (1=“A”, 2=“B”), resid.ds (1=“no”, 2=“yes”) and ecog.ps (1=“good”, 2=“bad”), and age group with labels “old” (if age &gt;=50) or “young” (otherwise). Create a survival object from futime and fustat, and print it. How many censored observations there are? Use the survival object created in the previous exercise to fit a KM curve for each treatment group, and plot them using option risk.table = TRUE in the ggsurvplot() function call. How many patients were at risk at 600 days? What are the median survival times of ovarian cancer in each treatment group? And what are the survival estimates at 1 and 2 years? Compare the two survival curves with a log-rank test. Does the suvival of ovarian cancer depend on the residual disease? Plot the survival curve for each residual disease group, so that the result of the log-rank test is shown in the graphic. Fit a Cox PH model with the treatment group, residual disease, age group, and ECOG performance status as explanatory variables. Is the proportional hazards assumption reasonable? Plot the hazard rates and corresponding 95% CI for all explanatory variables in the model. What of the explanatory variables are good and bad prognostic factors? "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
